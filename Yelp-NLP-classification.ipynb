{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Prediction Model - Yelp Reviews\n",
    "\n",
    "### Overview\n",
    "0. Features selected for DataFrame in previous notebook - Yelp-NLP-Preprocessing \n",
    "1. Perform EDA on classified Yelp data of reviews and businesses - target variable whether business is open\n",
    "1. Predict whether business is open based off reviews, and focus on false positives, indicated a business may be susceptible to closing\n",
    "1. Separate notebooks for determining themes amongst the businesses falling under false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic packages\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "#NLP pre-processing packages\n",
    "import nltk \n",
    "import re\n",
    "from nltk import WordNetLemmatizer, pos_tag # lemmatizer using WordNet, nltk's native part of speech tagging\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.tokenize import sent_tokenize \n",
    "from nltk.corpus import stopwords, wordnet # imports WordNet and stopwords\n",
    "#unhash below if not installed\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "#packages from class creation exercise\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#model packages\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer #used for analysis, but in general is a legacy package\n",
    "\n",
    "#model packages\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix, ConfusionMatrixDisplay,RocCurveDisplay,roc_auc_score\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA on Yelp Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>business_rating_avg</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great breakfast. Cute location and generally j...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>642</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I totally agree with Edward D. My kids and I w...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Super amazing food top notch. Best lobster rol...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cook with your heart, think with your head, pl...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>819</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SAB Cafe is right in the thick of the downtown...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  review_rating  \\\n",
       "0  Great breakfast. Cute location and generally j...            4.0   \n",
       "1  I totally agree with Edward D. My kids and I w...            1.0   \n",
       "2  Super amazing food top notch. Best lobster rol...            5.0   \n",
       "3  Cook with your heart, think with your head, pl...            2.0   \n",
       "4  SAB Cafe is right in the thick of the downtown...            4.0   \n",
       "\n",
       "   business_rating_avg  review_count  is_open  \n",
       "0                  4.0           642        1  \n",
       "1                  4.0            93        1  \n",
       "2                  3.0            76        1  \n",
       "3                  4.5           819        1  \n",
       "4                  4.0           199        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../test_yelp.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1199046\n",
       "0    1199046\n",
       "Name: is_open, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_open'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_rating</th>\n",
       "      <th>business_rating_avg</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>review_rating</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.484387</td>\n",
       "      <td>0.075113</td>\n",
       "      <td>0.052166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business_rating_avg</th>\n",
       "      <td>0.484387</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.145972</td>\n",
       "      <td>0.106196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_count</th>\n",
       "      <td>0.075113</td>\n",
       "      <td>0.145972</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.199750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_open</th>\n",
       "      <td>0.052166</td>\n",
       "      <td>0.106196</td>\n",
       "      <td>0.199750</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     review_rating  business_rating_avg  review_count  \\\n",
       "review_rating             1.000000             0.484387      0.075113   \n",
       "business_rating_avg       0.484387             1.000000      0.145972   \n",
       "review_count              0.075113             0.145972      1.000000   \n",
       "is_open                   0.052166             0.106196      0.199750   \n",
       "\n",
       "                      is_open  \n",
       "review_rating        0.052166  \n",
       "business_rating_avg  0.106196  \n",
       "review_count         0.199750  \n",
       "is_open              1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    57\n",
       "1    43\n",
       "Name: is_open, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a sample dataframe to test preprocessing classes and functions before feeding in entire dataset\n",
    "samp_df = df.sample(frac=1.0).head(100)\n",
    "samp_df['is_open'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class creation for future tweet cleaning:\n",
    "\n",
    "1. Lemmatizing class provided by Flatiron lecture - fine-tuned for this dataset\n",
    "1. Stemming class to be tweaked based off lemmatizing base Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a class to stem the texts - given large dataset, faster compared to lemmatizing\n",
    "#FOR FUTURE: move variables that are hashed into __init__ function\n",
    "class TextPreprocessorSTEM(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):  #, language='english'):\n",
    "        #self.stemmer = SnowballStemmer(language)\n",
    "        #self.stop_words = set(stopwords.words(language))\n",
    "        pass\n",
    "    \n",
    "    def fit(self, data, y = 0):\n",
    "        # this is where you would fit things like corpus specific stopwords\n",
    "        # fit probable bigrams with bigram model in here\n",
    "        \n",
    "        # save as parameters of Text preprocessor\n",
    "        \n",
    "        return self        \n",
    "        \n",
    "    def transform(self, data, y = 0):\n",
    "        fully_normalized_corpus = data.apply(self.process_doc)\n",
    "        return fully_normalized_corpus\n",
    "       \n",
    "    def process_doc(self, doc):\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "        # Tokenize the text\n",
    "        doc = re.sub(text_cleaning_re, ' ', str(doc).lower()).strip()\n",
    "        doc_norm = [tok.lower() for tok in word_tokenize(doc) if ((tok.isalpha()) & (tok not in stop_words)) ]    \n",
    "        # Apply stemming using Snowball Stemmer\n",
    "        stemmed_words = [stemmer.stem(word) for word in doc_norm if word not in stop_words]\n",
    "        return \" \".join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline class that lemmatizes text\n",
    "class TextPreprocessorLEM(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        #define attributes to store if text preprocessing requires fitting from data\n",
    "        pass\n",
    "    \n",
    "    def fit(self, data, y = 0):\n",
    "        # this is where you would fit things like corpus specific stopwords\n",
    "        # fit probable bigrams with bigram model in here\n",
    "        \n",
    "        # save as parameters of Text preprocessor\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, data, y = 0):\n",
    "        fully_normalized_corpus = data.apply(self.process_doc)\n",
    "        \n",
    "        return fully_normalized_corpus\n",
    "        \n",
    "    \n",
    "    def process_doc(self, doc):\n",
    "\n",
    "        #initialize lemmatizer\n",
    "        wnl = WordNetLemmatizer()\n",
    "        stop_words = stopwords.words('english')\n",
    "        \n",
    "        # helper function to change nltk's part of speech tagging to a wordnet format.\n",
    "        def pos_tagger(nltk_tag):\n",
    "            if nltk_tag.startswith('J'):\n",
    "                return wordnet.ADJ\n",
    "            elif nltk_tag.startswith('V'):\n",
    "                return wordnet.VERB\n",
    "            elif nltk_tag.startswith('N'):\n",
    "                return wordnet.NOUN\n",
    "            elif nltk_tag.startswith('R'):\n",
    "                return wordnet.ADV\n",
    "            else:         \n",
    "                return None\n",
    "\n",
    "        #text cleaning with re:\n",
    "        text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "        #\"@\\S+\" : Matches one or more non-whitespace characters after \"@\".\n",
    "        #\"https?:\\S+|http?:\\S:\" This part of the pattern matches URLs starting with \"http\" or \"https\".\n",
    "        #[^A-Za-z0-9]+: This part of the pattern matches any non-alphanumeric character.    \n",
    "                   \n",
    "        #remove URL's and tagged users (using the @ symbol), lower-cases the text, and gets rid of all spaces\n",
    "        doc = re.sub(text_cleaning_re, ' ', str(doc).lower()).strip()\n",
    "        # remove stop words and punctuations, then lower case\n",
    "        doc_norm = [tok.lower() for tok in word_tokenize(doc) if ((tok.isalpha()) & (tok not in stop_words)) ]\n",
    "        \n",
    "        #  POS detection on the result will be important in telling Wordnet's lemmatizer how to lemmatize\n",
    "\n",
    "        # creates list of tuples with tokens and POS tags in wordnet format\n",
    "        wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tag(doc_norm))) \n",
    "        doc_norm = [wnl.lemmatize(token, pos) for token, pos in wordnet_tagged if pos is not None]\n",
    "\n",
    "        return \" \".join(doc_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the function for future use\n",
    "proc_stem = TextPreprocessorSTEM()\n",
    "proc_lem = TextPreprocessorLEM()\n",
    "\n",
    "# Serialize the class object and save it to a file\n",
    "with open('TextPreprocessorSTEM.pkl', 'wb') as file_stem:\n",
    "    pickle.dump(proc_stem, file_stem)\n",
    "    \n",
    "with open('TextPreprocessorLEM.pkl', 'wb') as file_lem:\n",
    "    pickle.dump(proc_lem, file_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_stem = TextPreprocessorSTEM()\n",
    "with open('TextPreprocessorSTEM.pkl', 'wb') as file_stem:\n",
    "    pickle.dump(proc_stem, file_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the class performance on the sample dataframe\n",
    "X = samp_df['text']\n",
    "proc_stem = TextPreprocessorSTEM()\n",
    "proc_lem = TextPreprocessorLEM()\n",
    "transformed_X_stem = proc_stem.fit_transform(X) \n",
    "transformed_X_lem = proc_lem.fit_transform(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591267     got stay one night say everyth experi perfect ...\n",
       "1805446    disappoint experi wife went lunch date birthda...\n",
       "1795994          great diner great valu wonder servic danica\n",
       "1542021    best flea market lot cloth bling shop nsw equi...\n",
       "1360211    food excel fresh could share lunch portion stu...\n",
       "                                 ...                        \n",
       "277888     realli want like place love bowl locat great p...\n",
       "187396     place serious awesom indian food authent mani ...\n",
       "1178525    parent hype restaur week rave food week unsati...\n",
       "996227     use pep boy delawar ave year first period year...\n",
       "33371      place worth hype see differ advertis feed vent...\n",
       "Name: text, Length: 100, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_X_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591267     get stay night say everything experience perfe...\n",
       "1805446    disappointing experience wife go lunch date bi...\n",
       "1795994     great diner great value wonderful service danica\n",
       "1542021    best flea market lot clothes bling shop nsw eq...\n",
       "1360211    food excellent fresh share lunch portion stuff...\n",
       "                                 ...                        \n",
       "277888     really want place love bowl location great pri...\n",
       "187396     place seriously awesome indian food authentic ...\n",
       "1178525    parent hype restaurant week rave food week uns...\n",
       "996227     use pep boy delaware ave year first period yea...\n",
       "33371      place worth hype see different advertisement f...\n",
       "Name: text, Length: 100, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_X_lem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion on pre-processing class:\n",
    "\n",
    "It appears to be working ok on the sample data to get the data in the right format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#holdout test set for final evaluation - ensure no data leakage throughout iterative model process\n",
    "features = df.drop('is_open', axis=1)\n",
    "target = df['is_open']\n",
    "other_cols = ['review_rating', 'business_rating_avg', 'review_count']\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(features, target, test_size = 0.2, random_state = 53)\n",
    "\n",
    "train_df = pd.DataFrame(data=X)\n",
    "train_df['is_open'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    528\n",
       "0    472\n",
       "Name: is_open, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_df1 = train_df.sample(frac=1.0).head(1000)\n",
    "samp_df1['is_open'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data size: 800\n",
      "Test Data size 200\n"
     ]
    }
   ],
   "source": [
    "#perform the train-test split \n",
    "X1 = samp_df1.drop('is_open', axis=1)\n",
    "y1 = samp_df1['is_open']\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size = 0.2, random_state = 53)\n",
    "\n",
    "print(\"Train Data size:\", len(X_train1))\n",
    "print(\"Test Data size\", len(X_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess X_train with the two classes\n",
    "#create instances of all processors:\n",
    "proc_stem = TextPreprocessorSTEM()\n",
    "proc_lem = TextPreprocessorLEM()\n",
    "\n",
    "#create dataframes with Stemmed data\n",
    "X_train_stem1 = proc_stem.fit_transform(X_train1['text'])\n",
    "test_stem1 = proc_stem.transform(X_test1['text'])\n",
    "\n",
    "#create dataframes with lemmed data\n",
    "X_train_lem1 = proc_lem.fit_transform(X_train1['text']) \n",
    "test_lem1 = proc_lem.transform(X_test1['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the different models and parameters using GridSearchCV:\n",
    "\n",
    "Text preprocessing methods:\n",
    "1. Stemming (snowball) - done in preprocessing\n",
    "1. Lemmatizing (using WordNetLem) - done in preprocessing\n",
    "\n",
    "Vectorizers:\n",
    "1. Count Vectorizer\n",
    "1. Tf-Idf Vectorizers\n",
    "\n",
    "Models to run:\n",
    "1. Logistic Regression\n",
    "1. Simple Decision Tree Classifier\n",
    "1. Random Forest classifier\n",
    "1. Multinomial Naive Bayes\n",
    "1. Gradient-boosted Trees\n",
    "\n",
    "Pipelines to run:\n",
    "1. full GridSearchCV on sample of dataset (`n=1,000`)\n",
    "1. determine best combinations (`n=?`), and run second round of GridSearchCV by top `n` models with larger sample (`n=10,000`)\n",
    "1. narrow down best combinations to feed into third iteration of sample size (`n=100,000`)\n",
    "1. best combination of above to feed entire dataset into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 997)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer1_1a = CountVectorizer(min_df=0.01, max_df=0.99, ngram_range=(1, 10))\n",
    "X_1_1a = vectorizer1_1a.fit_transform(X_train_stem1)\n",
    "X_1_1a = pd.DataFrame.sparse.from_spmatrix(X_1_1a)\n",
    "X_1_1a = pd.concat([X_train1[other_cols].reset_index(drop=True), X_1_1a], axis=1)\n",
    "X_1_1a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 997)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer1_1b = TfidfVectorizer(min_df=0.01, max_df=0.99, ngram_range=(1, 10))\n",
    "X_1_1b = vectorizer1_1b.fit_transform(X_train_stem1)\n",
    "X_1_1b = pd.DataFrame.sparse.from_spmatrix(X_1_1b)\n",
    "X_1_1b = pd.concat([X_train1[other_cols].reset_index(drop=True), X_1_1b], axis=1)\n",
    "X_1_1b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 930)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer1_2a = CountVectorizer(min_df=0.01, max_df=0.99, ngram_range=(1, 10))\n",
    "X_1_2a = vectorizer1_2a.fit_transform(X_train_lem1)\n",
    "X_1_2a = pd.DataFrame.sparse.from_spmatrix(X_1_2a)\n",
    "X_1_2a = pd.concat([X_train1[other_cols].reset_index(drop=True), X_1_2a], axis=1)\n",
    "X_1_2a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 930)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer1_2b = TfidfVectorizer(min_df=0.01, max_df=0.99, ngram_range=(1, 10))\n",
    "X_1_2b = vectorizer1_2b.fit_transform(X_train_lem1)\n",
    "X_1_2b = pd.DataFrame.sparse.from_spmatrix(X_1_2b)\n",
    "X_1_2b = pd.concat([X_train1[other_cols].reset_index(drop=True), X_1_2b], axis=1)\n",
    "X_1_2b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer dictionary\n",
    "#vectorizers = {\n",
    "#    'tfidf': TfidfVectorizer(),\n",
    "#    'count': CountVectorizer()\n",
    "#}\n",
    "\n",
    "#Models and respective hyper-parameters\n",
    "rs=53 #random state the same across models\n",
    "# Initialze the estimators\n",
    "clf1 = LogisticRegression(random_state=rs)\n",
    "clf2 = DecisionTreeClassifier(random_state=rs)\n",
    "clf3 = RandomForestClassifier(random_state=rs)\n",
    "clf4 = MultinomialNB()\n",
    "clf5 = GradientBoostingClassifier(random_state=rs)\n",
    "\n",
    "# Initiaze the hyperparameters for each dictionary\n",
    "param1 = {}\n",
    "#param1['vectorizer'] = list(vectorizers.values())\n",
    "#param1['vectorizer__ngram_range'] = [(1, 1), (1, 4)]\n",
    "param1['classifier'] = [clf1]\n",
    "param1['classifier__C'] = [.01, .1, 1, 10, 100]\n",
    "param1['classifier__penalty'] = ['l2']#, 'l1'], if we want to include lasso\n",
    "\n",
    "param2 = {}\n",
    "#param2['vectorizer'] = list(vectorizers.values())\n",
    "#param2['vectorizer__ngram_range'] = [(1, 1), (1, 4)]\n",
    "param2['classifier'] = [clf2]\n",
    "param2['classifier__max_depth'] = [5,10]\n",
    "param2['classifier__min_samples_split'] = [2,5,10]\n",
    "#param2['classifier__class_weight'] = [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\n",
    "\n",
    "param3 = {}\n",
    "#param3['vectorizer'] = list(vectorizers.values())\n",
    "#param3['vectorizer__ngram_range'] = [(1, 1), (1, 4)]\n",
    "param3['classifier'] = [clf3]\n",
    "param3['classifier__n_estimators'] = [10, 50, 100, 250]\n",
    "param3['classifier__max_depth'] = [5, 10]\n",
    "#param3['classifier__class_weight'] = [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\n",
    "\n",
    "param4 = {}\n",
    "#param4['vectorizer'] = list(vectorizers.values())\n",
    "#param4['vectorizer__ngram_range'] = [(1, 1), (1, 4)]\n",
    "param4['classifier'] = [clf4]\n",
    "param4['classifier__alpha'] = [0.1, 0.5, 1]\n",
    "\n",
    "param5 = {}\n",
    "#param5['vectorizer'] = list(vectorizers.values())\n",
    "#param5['vectorizer__ngram_range'] = [(1, 1), (1, 4)]\n",
    "param5['classifier'] = [clf5]\n",
    "param5['classifier__n_estimators'] = [10, 50, 100, 250]\n",
    "param5['classifier__max_depth'] = [5, 10, 20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pipeline for non-tuned models\n",
    "pipeline1 = Pipeline([\n",
    " #   ('vectorizer', None),\n",
    "    ('classifier', None)\n",
    "])\n",
    "\n",
    "params = [param1, param2, param3, param4, param5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV objects for each set of preprocessed data\n",
    "grid_search1_stem_a = GridSearchCV(pipeline1, \n",
    "                           params, \n",
    "                           scoring = 'accuracy',\n",
    "                           cv=3)\n",
    "grid_search1_stem_b = GridSearchCV(pipeline1, \n",
    "                           params, \n",
    "                           scoring = 'accuracy',\n",
    "                           cv=3)\n",
    "\n",
    "grid_search1_lem_a = GridSearchCV(pipeline1, \n",
    "                           params, \n",
    "                           scoring = 'accuracy',\n",
    "                           cv=3)\n",
    "\n",
    "grid_search1_lem_b = GridSearchCV(pipeline1, \n",
    "                           params, \n",
    "                           scoring = 'accuracy',\n",
    "                           cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of best model with standard parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=Pipeline(steps=[('classifier', None)]),\n",
       "             param_grid=[{'classifier': [LogisticRegression(random_state=53)],\n",
       "                          'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
       "                          'classifier__penalty': ['l2']},\n",
       "                         {'classifier': [DecisionTreeClassifier(random_state=53)],\n",
       "                          'classifier__max_depth': [5, 10],\n",
       "                          'classifier__min_samples_split': [2, 5, 10]},\n",
       "                         {'classifier': [RandomFore...ier(random_state=53)],\n",
       "                          'classifier__max_depth': [5, 10],\n",
       "                          'classifier__n_estimators': [10, 50, 100, 250]},\n",
       "                         {'classifier': [MultinomialNB()],\n",
       "                          'classifier__alpha': [0.1, 0.5, 1]},\n",
       "                         {'classifier': [GradientBoostingClassifier(max_depth=10,\n",
       "                                                                    n_estimators=250,\n",
       "                                                                    random_state=53)],\n",
       "                          'classifier__max_depth': [5, 10, 20],\n",
       "                          'classifier__n_estimators': [10, 50, 100, 250]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search1_stem_a.fit(X_1_1a, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=Pipeline(steps=[('classifier', None)]),\n",
       "             param_grid=[{'classifier': [LogisticRegression(random_state=53)],\n",
       "                          'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
       "                          'classifier__penalty': ['l2']},\n",
       "                         {'classifier': [DecisionTreeClassifier(random_state=53)],\n",
       "                          'classifier__max_depth': [5, 10],\n",
       "                          'classifier__min_samples_split': [2, 5, 10]},\n",
       "                         {'classifier': [RandomFore...\n",
       "                                                                n_estimators=250,\n",
       "                                                                random_state=53)],\n",
       "                          'classifier__max_depth': [5, 10],\n",
       "                          'classifier__n_estimators': [10, 50, 100, 250]},\n",
       "                         {'classifier': [MultinomialNB()],\n",
       "                          'classifier__alpha': [0.1, 0.5, 1]},\n",
       "                         {'classifier': [GradientBoostingClassifier(max_depth=10,\n",
       "                                                                    n_estimators=250,\n",
       "                                                                    random_state=53)],\n",
       "                          'classifier__max_depth': [5, 10, 20],\n",
       "                          'classifier__n_estimators': [10, 50, 100, 250]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search1_stem_b.fit(X_1_1b, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=Pipeline(steps=[('classifier', None)]),\n",
       "             param_grid=[{'classifier': [LogisticRegression(random_state=53)],\n",
       "                          'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
       "                          'classifier__penalty': ['l2']},\n",
       "                         {'classifier': [DecisionTreeClassifier(random_state=53)],\n",
       "                          'classifier__max_depth': [5, 10],\n",
       "                          'classifier__min_samples_split': [2, 5, 10]},\n",
       "                         {'classifier': [RandomFore...=10,\n",
       "                                                                n_estimators=250,\n",
       "                                                                random_state=53)],\n",
       "                          'classifier__max_depth': [5, 10],\n",
       "                          'classifier__n_estimators': [10, 50, 100, 250]},\n",
       "                         {'classifier': [MultinomialNB()],\n",
       "                          'classifier__alpha': [0.1, 0.5, 1]},\n",
       "                         {'classifier': [GradientBoostingClassifier(max_depth=10,\n",
       "                                                                    random_state=53)],\n",
       "                          'classifier__max_depth': [5, 10, 20],\n",
       "                          'classifier__n_estimators': [10, 50, 100, 250]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search1_lem_a.fit(X_1_2a, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:508: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_search1_lem_b.fit(X_1_2b, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Dataframe of results from stem and lem\n",
    "grid_search1_stem_df1 = pd.DataFrame(grid_search1_stem_a.cv_results_)\n",
    "grid_search1_stem_df2 = pd.DataFrame(grid_search1_stem_b.cv_results_)\n",
    "grid_search1_lem_df1 = pd.DataFrame(grid_search1_lem_a.cv_results_)\n",
    "grid_search1_lem_df2 = pd.DataFrame(grid_search1_lem_b.cv_results_)\n",
    "\n",
    "grid_search1_stem_df1['preprocessor'] = 'TextPreprocessorSTEM()'\n",
    "grid_search1_stem_df2['preprocessor'] = 'TextPreprocessorSTEM()'\n",
    "grid_search1_lem_df1['preprocessor'] = 'TextPreprocessorLEM()'\n",
    "grid_search1_lem_df2['preprocessor'] = 'TextPreprocessorLEM()'\n",
    "\n",
    "grid_search1_stem_df1['vectorizer'] = 'Count'\n",
    "grid_search1_stem_df2['vectorizer'] = 'Tf-Idf'\n",
    "grid_search1_lem_df1['vectorizer'] = 'Count'\n",
    "grid_search1_lem_df2['vectorizer'] = 'Tf-Idf'\n",
    "\n",
    "grid_search1_df = pd.concat([grid_search1_lem_df1, grid_search1_lem_df2, grid_search1_stem_df1, grid_search1_stem_df2], axis=0, ignore_index=True)\n",
    "grid_search1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.606917</td>\n",
       "      <td>0.179857</td>\n",
       "      <td>0.052820</td>\n",
       "      <td>0.005988</td>\n",
       "      <td>0.579588</td>\n",
       "      <td>0.552930</td>\n",
       "      <td>0.578422</td>\n",
       "      <td>0.570313</td>\n",
       "      <td>0.021815</td>\n",
       "      <td>17.441176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.790095</td>\n",
       "      <td>0.522450</td>\n",
       "      <td>0.014035</td>\n",
       "      <td>0.006673</td>\n",
       "      <td>0.029167</td>\n",
       "      <td>0.033619</td>\n",
       "      <td>0.033784</td>\n",
       "      <td>0.023951</td>\n",
       "      <td>0.011839</td>\n",
       "      <td>9.765976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.266787</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.031336</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.483146</td>\n",
       "      <td>0.483146</td>\n",
       "      <td>0.492481</td>\n",
       "      <td>0.512503</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.343674</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.045734</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.565543</td>\n",
       "      <td>0.524345</td>\n",
       "      <td>0.555451</td>\n",
       "      <td>0.555308</td>\n",
       "      <td>0.012273</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.450981</td>\n",
       "      <td>0.022223</td>\n",
       "      <td>0.047390</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.580524</td>\n",
       "      <td>0.544944</td>\n",
       "      <td>0.580827</td>\n",
       "      <td>0.571858</td>\n",
       "      <td>0.020007</td>\n",
       "      <td>17.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.106938</td>\n",
       "      <td>0.107449</td>\n",
       "      <td>0.056671</td>\n",
       "      <td>0.007347</td>\n",
       "      <td>0.599251</td>\n",
       "      <td>0.580524</td>\n",
       "      <td>0.601504</td>\n",
       "      <td>0.582531</td>\n",
       "      <td>0.031025</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16.719722</td>\n",
       "      <td>4.220048</td>\n",
       "      <td>0.115906</td>\n",
       "      <td>0.038609</td>\n",
       "      <td>0.636704</td>\n",
       "      <td>0.625468</td>\n",
       "      <td>0.676692</td>\n",
       "      <td>0.628805</td>\n",
       "      <td>0.050476</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "count     136.000000    136.000000       136.000000      136.000000   \n",
       "mean        1.606917      0.179857         0.052820        0.005988   \n",
       "std         2.790095      0.522450         0.014035        0.006673   \n",
       "min         0.266787      0.000033         0.031336        0.000004   \n",
       "25%         0.343674      0.007880         0.045734        0.000985   \n",
       "50%         0.450981      0.022223         0.047390        0.005333   \n",
       "75%         1.106938      0.107449         0.056671        0.007347   \n",
       "max        16.719722      4.220048         0.115906        0.038609   \n",
       "\n",
       "       split0_test_score  split1_test_score  split2_test_score  \\\n",
       "count         136.000000         136.000000         136.000000   \n",
       "mean            0.579588           0.552930           0.578422   \n",
       "std             0.029167           0.033619           0.033784   \n",
       "min             0.483146           0.483146           0.492481   \n",
       "25%             0.565543           0.524345           0.555451   \n",
       "50%             0.580524           0.544944           0.580827   \n",
       "75%             0.599251           0.580524           0.601504   \n",
       "max             0.636704           0.625468           0.676692   \n",
       "\n",
       "       mean_test_score  std_test_score  rank_test_score  \n",
       "count       136.000000      136.000000       136.000000  \n",
       "mean          0.570313        0.021815        17.441176  \n",
       "std           0.023951        0.011839         9.765976  \n",
       "min           0.512503        0.001535         1.000000  \n",
       "25%           0.555308        0.012273         9.000000  \n",
       "50%           0.571858        0.020007        17.500000  \n",
       "75%           0.582531        0.031025        26.000000  \n",
       "max           0.628805        0.050476        34.000000  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search1_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search1_df = grid_search1_df.sort_values(by='mean_test_score', ascending=False).head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=10, random_state=53)    18\n",
       "LogisticRegression(C=1, random_state=53)                     15\n",
       "RandomForestClassifier(random_state=53)                       4\n",
       "MultinomialNB()                                               2\n",
       "DecisionTreeClassifier(random_state=53)                       1\n",
       "Name: param_classifier, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search1_df['param_classifier'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextPreprocessorSTEM()    25\n",
       "TextPreprocessorLEM()     15\n",
       "Name: preprocessor, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search1_df['preprocessor'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Count     21\n",
       "Tf-Idf    19\n",
       "Name: vectorizer, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search1_df['vectorizer'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Pipeline again with a slightly higher sample size, to see if rankings of GridSearchCV have changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5049\n",
       "1    4951\n",
       "Name: is_open, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slightly higher sample size\n",
    "samp_df2 = train_df.sample(frac=1.0).head(10000)\n",
    "samp_df2['is_open'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform the train-test split \n",
    "X2 = samp_df2.drop('is_open', axis=1)\n",
    "y2 = samp_df2['is_open']\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size = 0.2, random_state = 53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline([('classifier', None)])\n",
    "#grid_search2_lem_a = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV objects for each set of preprocessed data\n",
    "params2 = [param5, param1] #choosing top 2 models from above gridsearch for efficiency\n",
    "grid_search2_stem_a = GridSearchCV(pipeline2, params2, scoring = 'accuracy', cv=3)\n",
    "grid_search2_stem_b = GridSearchCV(pipeline2, params2, scoring = 'accuracy', cv=3)\n",
    "grid_search2_lem_a = GridSearchCV(pipeline2, params2, scoring = 'accuracy', cv=3)\n",
    "grid_search2_lem_b = GridSearchCV(pipeline2, params2, scoring = 'accuracy', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess X_train with the two classes\n",
    "#create instances of all processors:\n",
    "proc_stem2 = TextPreprocessorSTEM()\n",
    "proc_lem2 = TextPreprocessorLEM()\n",
    "\n",
    "#create dataframes with Stemmed data\n",
    "X_train_stem2 = proc_stem2.fit_transform(X_train2['text'])\n",
    "test_stem2 = proc_stem2.transform(X_test2['text'])\n",
    "\n",
    "#create dataframes with lemmed data\n",
    "X_train_lem2 = proc_lem2.fit_transform(X_train2['text']) \n",
    "test_lem2 = proc_lem2.transform(X_test2['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357672     kinda pricey overal clean well maintain locat ...\n",
       "336860     amaz freshest seafood simpli best wasabi plane...\n",
       "419032     friend go bauhaus quit time occasion go staff ...\n",
       "1620969    new name feast recent owner noth chang great f...\n",
       "1728626    compact spa gym avail local well guest hotel t...\n",
       "                                 ...                        \n",
       "388886     dinner twice drink unfortun disappoint time dr...\n",
       "693475     second time month order deliveri disappoint de...\n",
       "2261422    still one favorit place nice famili environ fo...\n",
       "408966     tini mighti wine bar one favorit date night sp...\n",
       "1807300    visit tampa weekend friend decid tri streetcar...\n",
       "Name: text, Length: 8000, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_stem2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 902)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2_1a = CountVectorizer(min_df=0.01, max_df=0.99, ngram_range=(1, 5))\n",
    "X_2_1a = vectorizer2_1a.fit_transform(X_train_stem2)\n",
    "X_2_1a = pd.DataFrame.sparse.from_spmatrix(X_2_1a)\n",
    "X_2_1a = pd.concat([X_train2[other_cols].reset_index(drop=True), X_2_1a], axis=1)\n",
    "X_2_1a = csr_matrix(X_2_1a.values)\n",
    "\n",
    "X_2_1a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 902)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2_1b = TfidfVectorizer(min_df=0.01, max_df=0.99, ngram_range=(1, 5))\n",
    "X_2_1b = vectorizer2_1b.fit_transform(X_train_stem2)\n",
    "X_2_1b = pd.DataFrame.sparse.from_spmatrix(X_2_1b)\n",
    "X_2_1b = pd.concat([X_train2[other_cols].reset_index(drop=True), X_2_1b], axis=1)\n",
    "X_2_1b = csr_matrix(X_2_1b.values)\n",
    "\n",
    "X_2_1b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 841)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2_2a = CountVectorizer(min_df=0.01, max_df=0.99, ngram_range=(1, 5))\n",
    "X_2_2a = vectorizer2_2a.fit_transform(X_train_lem2)\n",
    "X_2_2a = pd.DataFrame.sparse.from_spmatrix(X_2_2a)\n",
    "X_2_2a = pd.concat([X_train2[other_cols].reset_index(drop=True), X_2_2a], axis=1)\n",
    "X_2_2a = csr_matrix(X_2_2a.values)\n",
    "\n",
    "X_2_2a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 841)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2_2b = TfidfVectorizer(min_df=0.01, max_df=0.99, ngram_range=(1, 5))\n",
    "X_2_2b = vectorizer2_2b.fit_transform(X_train_lem2)\n",
    "X_2_2b = pd.DataFrame.sparse.from_spmatrix(X_2_2b)\n",
    "X_2_2b = pd.concat([X_train2[other_cols].reset_index(drop=True), X_2_2b], axis=1)\n",
    "X_2_2b = csr_matrix(X_2_2b.values)\n",
    "X_2_2b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=Pipeline(steps=[('classifier', None)]),\n",
       "             param_grid=[{'classifier': [GradientBoostingClassifier(max_depth=5,\n",
       "                                                                    n_estimators=250,\n",
       "                                                                    random_state=53)],\n",
       "                          'classifier__max_depth': [5, 10, 20],\n",
       "                          'classifier__n_estimators': [10, 50, 100, 250]},\n",
       "                         {'classifier': [LogisticRegression(C=1,\n",
       "                                                            random_state=53)],\n",
       "                          'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
       "                          'classifier__penalty': ['l2']}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search2_stem_a.fit(X_2_1a, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=Pipeline(steps=[('classifier', None)]),\n",
       "             param_grid=[{'classifier': [GradientBoostingClassifier(max_depth=5,\n",
       "                                                                    n_estimators=250,\n",
       "                                                                    random_state=53)],\n",
       "                          'classifier__max_depth': [5, 10, 20],\n",
       "                          'classifier__n_estimators': [10, 50, 100, 250]},\n",
       "                         {'classifier': [LogisticRegression(C=0.1,\n",
       "                                                            random_state=53)],\n",
       "                          'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
       "                          'classifier__penalty': ['l2']}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search2_stem_b.fit(X_2_1b, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=Pipeline(steps=[('classifier', None)]),\n",
       "             param_grid=[{'classifier': [GradientBoostingClassifier(max_depth=10,\n",
       "                                                                    n_estimators=50,\n",
       "                                                                    random_state=53)],\n",
       "                          'classifier__max_depth': [5, 10, 20],\n",
       "                          'classifier__n_estimators': [10, 50, 100, 250]},\n",
       "                         {'classifier': [LogisticRegression(C=0.1,\n",
       "                                                            random_state=53)],\n",
       "                          'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
       "                          'classifier__penalty': ['l2']}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the grid search\n",
    "grid_search2_lem_a.fit(X_2_2a, y_train2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Reid Majka\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=Pipeline(steps=[('classifier', None)]),\n",
       "             param_grid=[{'classifier': [GradientBoostingClassifier(max_depth=10,\n",
       "                                                                    n_estimators=50,\n",
       "                                                                    random_state=53)],\n",
       "                          'classifier__max_depth': [5, 10, 20],\n",
       "                          'classifier__n_estimators': [10, 50, 100, 250]},\n",
       "                         {'classifier': [LogisticRegression(C=0.1,\n",
       "                                                            random_state=53)],\n",
       "                          'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
       "                          'classifier__penalty': ['l2']}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the grid search\n",
    "grid_search2_lem_b.fit(X_2_2b, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier</th>\n",
       "      <th>param_classifier__C</th>\n",
       "      <th>param_classifier__penalty</th>\n",
       "      <th>param_classifier__max_depth</th>\n",
       "      <th>param_classifier__min_samples_split</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>param_classifier__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>preprocessor</th>\n",
       "      <th>vectorizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.362924</td>\n",
       "      <td>0.013806</td>\n",
       "      <td>0.044625</td>\n",
       "      <td>0.012170</td>\n",
       "      <td>LogisticRegression(C=0.1, random_state=53)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': LogisticRegression(C=0.1, rando...</td>\n",
       "      <td>0.625468</td>\n",
       "      <td>0.606742</td>\n",
       "      <td>0.601504</td>\n",
       "      <td>0.611238</td>\n",
       "      <td>0.010287</td>\n",
       "      <td>2</td>\n",
       "      <td>TextPreprocessorLEM()</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.351466</td>\n",
       "      <td>0.006692</td>\n",
       "      <td>0.043023</td>\n",
       "      <td>0.006147</td>\n",
       "      <td>LogisticRegression(C=0.1, random_state=53)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': LogisticRegression(C=0.1, rando...</td>\n",
       "      <td>0.636704</td>\n",
       "      <td>0.610487</td>\n",
       "      <td>0.609023</td>\n",
       "      <td>0.618738</td>\n",
       "      <td>0.012718</td>\n",
       "      <td>1</td>\n",
       "      <td>TextPreprocessorLEM()</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.354373</td>\n",
       "      <td>0.016130</td>\n",
       "      <td>0.045064</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>LogisticRegression(C=0.1, random_state=53)</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': LogisticRegression(C=0.1, rando...</td>\n",
       "      <td>0.621723</td>\n",
       "      <td>0.588015</td>\n",
       "      <td>0.567669</td>\n",
       "      <td>0.592469</td>\n",
       "      <td>0.022291</td>\n",
       "      <td>5</td>\n",
       "      <td>TextPreprocessorLEM()</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.353977</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>0.046343</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>LogisticRegression(C=0.1, random_state=53)</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': LogisticRegression(C=0.1, rando...</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.621723</td>\n",
       "      <td>0.582707</td>\n",
       "      <td>0.607469</td>\n",
       "      <td>0.017576</td>\n",
       "      <td>3</td>\n",
       "      <td>TextPreprocessorLEM()</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.346576</td>\n",
       "      <td>0.006488</td>\n",
       "      <td>0.045239</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>LogisticRegression(C=0.1, random_state=53)</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': LogisticRegression(C=0.1, rando...</td>\n",
       "      <td>0.591760</td>\n",
       "      <td>0.584270</td>\n",
       "      <td>0.560150</td>\n",
       "      <td>0.578727</td>\n",
       "      <td>0.013487</td>\n",
       "      <td>15</td>\n",
       "      <td>TextPreprocessorLEM()</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.362924      0.013806         0.044625        0.012170   \n",
       "1       0.351466      0.006692         0.043023        0.006147   \n",
       "2       0.354373      0.016130         0.045064        0.006104   \n",
       "3       0.353977      0.006639         0.046343        0.000741   \n",
       "4       0.346576      0.006488         0.045239        0.002328   \n",
       "\n",
       "                             param_classifier param_classifier__C  \\\n",
       "0  LogisticRegression(C=0.1, random_state=53)                0.01   \n",
       "1  LogisticRegression(C=0.1, random_state=53)                 0.1   \n",
       "2  LogisticRegression(C=0.1, random_state=53)                   1   \n",
       "3  LogisticRegression(C=0.1, random_state=53)                  10   \n",
       "4  LogisticRegression(C=0.1, random_state=53)                 100   \n",
       "\n",
       "  param_classifier__penalty param_classifier__max_depth  \\\n",
       "0                        l2                         NaN   \n",
       "1                        l2                         NaN   \n",
       "2                        l2                         NaN   \n",
       "3                        l2                         NaN   \n",
       "4                        l2                         NaN   \n",
       "\n",
       "  param_classifier__min_samples_split param_classifier__n_estimators  \\\n",
       "0                                 NaN                            NaN   \n",
       "1                                 NaN                            NaN   \n",
       "2                                 NaN                            NaN   \n",
       "3                                 NaN                            NaN   \n",
       "4                                 NaN                            NaN   \n",
       "\n",
       "  param_classifier__alpha                                             params  \\\n",
       "0                     NaN  {'classifier': LogisticRegression(C=0.1, rando...   \n",
       "1                     NaN  {'classifier': LogisticRegression(C=0.1, rando...   \n",
       "2                     NaN  {'classifier': LogisticRegression(C=0.1, rando...   \n",
       "3                     NaN  {'classifier': LogisticRegression(C=0.1, rando...   \n",
       "4                     NaN  {'classifier': LogisticRegression(C=0.1, rando...   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0           0.625468           0.606742           0.601504         0.611238   \n",
       "1           0.636704           0.610487           0.609023         0.618738   \n",
       "2           0.621723           0.588015           0.567669         0.592469   \n",
       "3           0.617978           0.621723           0.582707         0.607469   \n",
       "4           0.591760           0.584270           0.560150         0.578727   \n",
       "\n",
       "   std_test_score  rank_test_score           preprocessor vectorizer  \n",
       "0        0.010287                2  TextPreprocessorLEM()      Count  \n",
       "1        0.012718                1  TextPreprocessorLEM()      Count  \n",
       "2        0.022291                5  TextPreprocessorLEM()      Count  \n",
       "3        0.017576                3  TextPreprocessorLEM()      Count  \n",
       "4        0.013487               15  TextPreprocessorLEM()      Count  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create Dataframe of results from stem and lem\n",
    "grid_search2_stem_df1 = pd.DataFrame(grid_search2_stem_a.cv_results_)\n",
    "grid_search2_stem_df2 = pd.DataFrame(grid_search2_stem_b.cv_results_)\n",
    "grid_search2_lem_df1 = pd.DataFrame(grid_search2_lem_a.cv_results_)\n",
    "grid_search2_lem_df2 = pd.DataFrame(grid_search2_lem_b.cv_results_)\n",
    "\n",
    "grid_search2_stem_df1['preprocessor'] = 'TextPreprocessorSTEM()'\n",
    "grid_search2_stem_df2['preprocessor'] = 'TextPreprocessorSTEM()'\n",
    "grid_search2_lem_df1['preprocessor'] = 'TextPreprocessorLEM()'\n",
    "grid_search2_lem_df2['preprocessor'] = 'TextPreprocessorLEM()'\n",
    "\n",
    "grid_search2_stem_df1['vectorizer'] = 'Count'\n",
    "grid_search2_stem_df2['vectorizer'] = 'Tf-Idf'\n",
    "grid_search2_lem_df1['vectorizer'] = 'Count'\n",
    "grid_search2_lem_df2['vectorizer'] = 'Tf-Idf'\n",
    "\n",
    "grid_search2_df = pd.concat([grid_search1_lem_df1, grid_search1_lem_df2, grid_search1_stem_df1, grid_search1_stem_df2], axis=0, ignore_index=True)\n",
    "grid_search2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier</th>\n",
       "      <th>param_classifier__C</th>\n",
       "      <th>param_classifier__penalty</th>\n",
       "      <th>param_classifier__max_depth</th>\n",
       "      <th>param_classifier__min_samples_split</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>param_classifier__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>preprocessor</th>\n",
       "      <th>vectorizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3.443423</td>\n",
       "      <td>0.035288</td>\n",
       "      <td>0.048177</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>GradientBoostingClassifier(max_depth=10, n_est...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': GradientBoostingClassifier(max_...</td>\n",
       "      <td>0.632959</td>\n",
       "      <td>0.580524</td>\n",
       "      <td>0.672932</td>\n",
       "      <td>0.628805</td>\n",
       "      <td>0.037840</td>\n",
       "      <td>1</td>\n",
       "      <td>TextPreprocessorSTEM()</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7.858234</td>\n",
       "      <td>0.168955</td>\n",
       "      <td>0.053147</td>\n",
       "      <td>0.006777</td>\n",
       "      <td>GradientBoostingClassifier(max_depth=10, n_est...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': GradientBoostingClassifier(max_...</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.588015</td>\n",
       "      <td>0.676692</td>\n",
       "      <td>0.627561</td>\n",
       "      <td>0.036831</td>\n",
       "      <td>2</td>\n",
       "      <td>TextPreprocessorSTEM()</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.351466</td>\n",
       "      <td>0.006692</td>\n",
       "      <td>0.043023</td>\n",
       "      <td>0.006147</td>\n",
       "      <td>LogisticRegression(C=0.1, random_state=53)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': LogisticRegression(C=0.1, rando...</td>\n",
       "      <td>0.636704</td>\n",
       "      <td>0.610487</td>\n",
       "      <td>0.609023</td>\n",
       "      <td>0.618738</td>\n",
       "      <td>0.012718</td>\n",
       "      <td>1</td>\n",
       "      <td>TextPreprocessorLEM()</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.351183</td>\n",
       "      <td>0.010422</td>\n",
       "      <td>0.041049</td>\n",
       "      <td>0.005330</td>\n",
       "      <td>LogisticRegression(C=0.1, random_state=53)</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': LogisticRegression(C=0.1, rando...</td>\n",
       "      <td>0.629213</td>\n",
       "      <td>0.625468</td>\n",
       "      <td>0.597744</td>\n",
       "      <td>0.617475</td>\n",
       "      <td>0.014035</td>\n",
       "      <td>1</td>\n",
       "      <td>TextPreprocessorLEM()</td>\n",
       "      <td>Tf-Idf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.495631</td>\n",
       "      <td>0.044476</td>\n",
       "      <td>0.055593</td>\n",
       "      <td>0.006990</td>\n",
       "      <td>LogisticRegression(C=0.1, random_state=53)</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': LogisticRegression(C=0.1, rando...</td>\n",
       "      <td>0.629213</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.590226</td>\n",
       "      <td>0.612472</td>\n",
       "      <td>0.016386</td>\n",
       "      <td>1</td>\n",
       "      <td>TextPreprocessorSTEM()</td>\n",
       "      <td>Tf-Idf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>4.261994</td>\n",
       "      <td>0.266465</td>\n",
       "      <td>0.050698</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>GradientBoostingClassifier(max_depth=10, n_est...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': GradientBoostingClassifier(max_...</td>\n",
       "      <td>0.606742</td>\n",
       "      <td>0.591760</td>\n",
       "      <td>0.635338</td>\n",
       "      <td>0.611280</td>\n",
       "      <td>0.018078</td>\n",
       "      <td>3</td>\n",
       "      <td>TextPreprocessorSTEM()</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.362924</td>\n",
       "      <td>0.013806</td>\n",
       "      <td>0.044625</td>\n",
       "      <td>0.012170</td>\n",
       "      <td>LogisticRegression(C=0.1, random_state=53)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': LogisticRegression(C=0.1, rando...</td>\n",
       "      <td>0.625468</td>\n",
       "      <td>0.606742</td>\n",
       "      <td>0.601504</td>\n",
       "      <td>0.611238</td>\n",
       "      <td>0.010287</td>\n",
       "      <td>2</td>\n",
       "      <td>TextPreprocessorLEM()</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.519306</td>\n",
       "      <td>0.045486</td>\n",
       "      <td>0.063021</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>LogisticRegression(C=0.1, random_state=53)</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': LogisticRegression(C=0.1, rando...</td>\n",
       "      <td>0.632959</td>\n",
       "      <td>0.584270</td>\n",
       "      <td>0.612782</td>\n",
       "      <td>0.610003</td>\n",
       "      <td>0.019974</td>\n",
       "      <td>2</td>\n",
       "      <td>TextPreprocessorSTEM()</td>\n",
       "      <td>Tf-Idf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.349784</td>\n",
       "      <td>0.014442</td>\n",
       "      <td>0.043508</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>LogisticRegression(C=0.1, random_state=53)</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': LogisticRegression(C=0.1, rando...</td>\n",
       "      <td>0.632959</td>\n",
       "      <td>0.599251</td>\n",
       "      <td>0.593985</td>\n",
       "      <td>0.608732</td>\n",
       "      <td>0.017266</td>\n",
       "      <td>2</td>\n",
       "      <td>TextPreprocessorLEM()</td>\n",
       "      <td>Tf-Idf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.442771</td>\n",
       "      <td>0.089492</td>\n",
       "      <td>0.049024</td>\n",
       "      <td>0.010705</td>\n",
       "      <td>LogisticRegression(C=0.1, random_state=53)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': LogisticRegression(C=0.1, rando...</td>\n",
       "      <td>0.632959</td>\n",
       "      <td>0.595506</td>\n",
       "      <td>0.593985</td>\n",
       "      <td>0.607483</td>\n",
       "      <td>0.018025</td>\n",
       "      <td>4</td>\n",
       "      <td>TextPreprocessorSTEM()</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.353977</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>0.046343</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>LogisticRegression(C=0.1, random_state=53)</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': LogisticRegression(C=0.1, rando...</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.621723</td>\n",
       "      <td>0.582707</td>\n",
       "      <td>0.607469</td>\n",
       "      <td>0.017576</td>\n",
       "      <td>3</td>\n",
       "      <td>TextPreprocessorLEM()</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2.073557</td>\n",
       "      <td>0.018505</td>\n",
       "      <td>0.055365</td>\n",
       "      <td>0.006392</td>\n",
       "      <td>GradientBoostingClassifier(max_depth=10, n_est...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': GradientBoostingClassifier(max_...</td>\n",
       "      <td>0.588015</td>\n",
       "      <td>0.621723</td>\n",
       "      <td>0.609023</td>\n",
       "      <td>0.606253</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>3</td>\n",
       "      <td>TextPreprocessorSTEM()</td>\n",
       "      <td>Tf-Idf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.839901</td>\n",
       "      <td>0.025584</td>\n",
       "      <td>0.047142</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>GradientBoostingClassifier(max_depth=10, n_est...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': GradientBoostingClassifier(max_...</td>\n",
       "      <td>0.588015</td>\n",
       "      <td>0.554307</td>\n",
       "      <td>0.672932</td>\n",
       "      <td>0.605085</td>\n",
       "      <td>0.049910</td>\n",
       "      <td>5</td>\n",
       "      <td>TextPreprocessorSTEM()</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.376497</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.041865</td>\n",
       "      <td>0.007239</td>\n",
       "      <td>LogisticRegression(C=0.1, random_state=53)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': LogisticRegression(C=0.1, rando...</td>\n",
       "      <td>0.595506</td>\n",
       "      <td>0.602996</td>\n",
       "      <td>0.612782</td>\n",
       "      <td>0.603761</td>\n",
       "      <td>0.007074</td>\n",
       "      <td>6</td>\n",
       "      <td>TextPreprocessorSTEM()</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2.302737</td>\n",
       "      <td>0.206263</td>\n",
       "      <td>0.054893</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>GradientBoostingClassifier(max_depth=10, n_est...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': GradientBoostingClassifier(max_...</td>\n",
       "      <td>0.629213</td>\n",
       "      <td>0.558052</td>\n",
       "      <td>0.609023</td>\n",
       "      <td>0.598763</td>\n",
       "      <td>0.029944</td>\n",
       "      <td>7</td>\n",
       "      <td>TextPreprocessorSTEM()</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.360643</td>\n",
       "      <td>0.001837</td>\n",
       "      <td>0.046521</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>LogisticRegression(C=0.1, random_state=53)</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': LogisticRegression(C=0.1, rando...</td>\n",
       "      <td>0.632959</td>\n",
       "      <td>0.573034</td>\n",
       "      <td>0.590226</td>\n",
       "      <td>0.598739</td>\n",
       "      <td>0.025194</td>\n",
       "      <td>3</td>\n",
       "      <td>TextPreprocessorLEM()</td>\n",
       "      <td>Tf-Idf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7.682316</td>\n",
       "      <td>0.664173</td>\n",
       "      <td>0.046897</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>GradientBoostingClassifier(max_depth=10, n_est...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': GradientBoostingClassifier(max_...</td>\n",
       "      <td>0.580524</td>\n",
       "      <td>0.580524</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.597543</td>\n",
       "      <td>0.024067</td>\n",
       "      <td>4</td>\n",
       "      <td>TextPreprocessorLEM()</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.334150</td>\n",
       "      <td>0.009034</td>\n",
       "      <td>0.042058</td>\n",
       "      <td>0.007339</td>\n",
       "      <td>LogisticRegression(C=0.1, random_state=53)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': LogisticRegression(C=0.1, rando...</td>\n",
       "      <td>0.599251</td>\n",
       "      <td>0.610487</td>\n",
       "      <td>0.582707</td>\n",
       "      <td>0.597482</td>\n",
       "      <td>0.011410</td>\n",
       "      <td>4</td>\n",
       "      <td>TextPreprocessorLEM()</td>\n",
       "      <td>Tf-Idf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1.195424</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.046551</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>GradientBoostingClassifier(max_depth=10, n_est...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': GradientBoostingClassifier(max_...</td>\n",
       "      <td>0.584270</td>\n",
       "      <td>0.591760</td>\n",
       "      <td>0.612782</td>\n",
       "      <td>0.596271</td>\n",
       "      <td>0.012069</td>\n",
       "      <td>4</td>\n",
       "      <td>TextPreprocessorSTEM()</td>\n",
       "      <td>Tf-Idf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>3.868705</td>\n",
       "      <td>0.032589</td>\n",
       "      <td>0.046193</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>GradientBoostingClassifier(max_depth=10, n_est...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': GradientBoostingClassifier(max_...</td>\n",
       "      <td>0.610487</td>\n",
       "      <td>0.584270</td>\n",
       "      <td>0.593985</td>\n",
       "      <td>0.596247</td>\n",
       "      <td>0.010822</td>\n",
       "      <td>5</td>\n",
       "      <td>TextPreprocessorSTEM()</td>\n",
       "      <td>Tf-Idf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "96        3.443423      0.035288         0.048177        0.000975   \n",
       "97        7.858234      0.168955         0.053147        0.006777   \n",
       "1         0.351466      0.006692         0.043023        0.006147   \n",
       "36        0.351183      0.010422         0.041049        0.005330   \n",
       "104       0.495631      0.044476         0.055593        0.006990   \n",
       "93        4.261994      0.266465         0.050698        0.001233   \n",
       "0         0.362924      0.013806         0.044625        0.012170   \n",
       "105       0.519306      0.045486         0.063021        0.002783   \n",
       "37        0.349784      0.014442         0.043508        0.005139   \n",
       "68        0.442771      0.089492         0.049024        0.010705   \n",
       "3         0.353977      0.006639         0.046343        0.000741   \n",
       "129       2.073557      0.018505         0.055365        0.006392   \n",
       "95        1.839901      0.025584         0.047142        0.000246   \n",
       "69        0.376497      0.002717         0.041865        0.007239   \n",
       "92        2.302737      0.206263         0.054893        0.002680   \n",
       "38        0.360643      0.001837         0.046521        0.002902   \n",
       "29        7.682316      0.664173         0.046897        0.000066   \n",
       "35        0.334150      0.009034         0.042058        0.007339   \n",
       "125       1.195424      0.009556         0.046551        0.000787   \n",
       "130       3.868705      0.032589         0.046193        0.000988   \n",
       "\n",
       "                                      param_classifier param_classifier__C  \\\n",
       "96   GradientBoostingClassifier(max_depth=10, n_est...                 NaN   \n",
       "97   GradientBoostingClassifier(max_depth=10, n_est...                 NaN   \n",
       "1           LogisticRegression(C=0.1, random_state=53)                 0.1   \n",
       "36          LogisticRegression(C=0.1, random_state=53)                   1   \n",
       "104         LogisticRegression(C=0.1, random_state=53)                   1   \n",
       "93   GradientBoostingClassifier(max_depth=10, n_est...                 NaN   \n",
       "0           LogisticRegression(C=0.1, random_state=53)                0.01   \n",
       "105         LogisticRegression(C=0.1, random_state=53)                  10   \n",
       "37          LogisticRegression(C=0.1, random_state=53)                  10   \n",
       "68          LogisticRegression(C=0.1, random_state=53)                0.01   \n",
       "3           LogisticRegression(C=0.1, random_state=53)                  10   \n",
       "129  GradientBoostingClassifier(max_depth=10, n_est...                 NaN   \n",
       "95   GradientBoostingClassifier(max_depth=10, n_est...                 NaN   \n",
       "69          LogisticRegression(C=0.1, random_state=53)                 0.1   \n",
       "92   GradientBoostingClassifier(max_depth=10, n_est...                 NaN   \n",
       "38          LogisticRegression(C=0.1, random_state=53)                 100   \n",
       "29   GradientBoostingClassifier(max_depth=10, n_est...                 NaN   \n",
       "35          LogisticRegression(C=0.1, random_state=53)                 0.1   \n",
       "125  GradientBoostingClassifier(max_depth=10, n_est...                 NaN   \n",
       "130  GradientBoostingClassifier(max_depth=10, n_est...                 NaN   \n",
       "\n",
       "    param_classifier__penalty param_classifier__max_depth  \\\n",
       "96                        NaN                          10   \n",
       "97                        NaN                          10   \n",
       "1                          l2                         NaN   \n",
       "36                         l2                         NaN   \n",
       "104                        l2                         NaN   \n",
       "93                        NaN                           5   \n",
       "0                          l2                         NaN   \n",
       "105                        l2                         NaN   \n",
       "37                         l2                         NaN   \n",
       "68                         l2                         NaN   \n",
       "3                          l2                         NaN   \n",
       "129                       NaN                          10   \n",
       "95                        NaN                          10   \n",
       "69                         l2                         NaN   \n",
       "92                        NaN                           5   \n",
       "38                         l2                         NaN   \n",
       "29                        NaN                          10   \n",
       "35                         l2                         NaN   \n",
       "125                       NaN                           5   \n",
       "130                       NaN                          10   \n",
       "\n",
       "    param_classifier__min_samples_split param_classifier__n_estimators  \\\n",
       "96                                  NaN                            100   \n",
       "97                                  NaN                            250   \n",
       "1                                   NaN                            NaN   \n",
       "36                                  NaN                            NaN   \n",
       "104                                 NaN                            NaN   \n",
       "93                                  NaN                            250   \n",
       "0                                   NaN                            NaN   \n",
       "105                                 NaN                            NaN   \n",
       "37                                  NaN                            NaN   \n",
       "68                                  NaN                            NaN   \n",
       "3                                   NaN                            NaN   \n",
       "129                                 NaN                             50   \n",
       "95                                  NaN                             50   \n",
       "69                                  NaN                            NaN   \n",
       "92                                  NaN                            100   \n",
       "38                                  NaN                            NaN   \n",
       "29                                  NaN                            250   \n",
       "35                                  NaN                            NaN   \n",
       "125                                 NaN                             50   \n",
       "130                                 NaN                            100   \n",
       "\n",
       "    param_classifier__alpha  \\\n",
       "96                      NaN   \n",
       "97                      NaN   \n",
       "1                       NaN   \n",
       "36                      NaN   \n",
       "104                     NaN   \n",
       "93                      NaN   \n",
       "0                       NaN   \n",
       "105                     NaN   \n",
       "37                      NaN   \n",
       "68                      NaN   \n",
       "3                       NaN   \n",
       "129                     NaN   \n",
       "95                      NaN   \n",
       "69                      NaN   \n",
       "92                      NaN   \n",
       "38                      NaN   \n",
       "29                      NaN   \n",
       "35                      NaN   \n",
       "125                     NaN   \n",
       "130                     NaN   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "96   {'classifier': GradientBoostingClassifier(max_...           0.632959   \n",
       "97   {'classifier': GradientBoostingClassifier(max_...           0.617978   \n",
       "1    {'classifier': LogisticRegression(C=0.1, rando...           0.636704   \n",
       "36   {'classifier': LogisticRegression(C=0.1, rando...           0.629213   \n",
       "104  {'classifier': LogisticRegression(C=0.1, rando...           0.629213   \n",
       "93   {'classifier': GradientBoostingClassifier(max_...           0.606742   \n",
       "0    {'classifier': LogisticRegression(C=0.1, rando...           0.625468   \n",
       "105  {'classifier': LogisticRegression(C=0.1, rando...           0.632959   \n",
       "37   {'classifier': LogisticRegression(C=0.1, rando...           0.632959   \n",
       "68   {'classifier': LogisticRegression(C=0.1, rando...           0.632959   \n",
       "3    {'classifier': LogisticRegression(C=0.1, rando...           0.617978   \n",
       "129  {'classifier': GradientBoostingClassifier(max_...           0.588015   \n",
       "95   {'classifier': GradientBoostingClassifier(max_...           0.588015   \n",
       "69   {'classifier': LogisticRegression(C=0.1, rando...           0.595506   \n",
       "92   {'classifier': GradientBoostingClassifier(max_...           0.629213   \n",
       "38   {'classifier': LogisticRegression(C=0.1, rando...           0.632959   \n",
       "29   {'classifier': GradientBoostingClassifier(max_...           0.580524   \n",
       "35   {'classifier': LogisticRegression(C=0.1, rando...           0.599251   \n",
       "125  {'classifier': GradientBoostingClassifier(max_...           0.584270   \n",
       "130  {'classifier': GradientBoostingClassifier(max_...           0.610487   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "96            0.580524           0.672932         0.628805        0.037840   \n",
       "97            0.588015           0.676692         0.627561        0.036831   \n",
       "1             0.610487           0.609023         0.618738        0.012718   \n",
       "36            0.625468           0.597744         0.617475        0.014035   \n",
       "104           0.617978           0.590226         0.612472        0.016386   \n",
       "93            0.591760           0.635338         0.611280        0.018078   \n",
       "0             0.606742           0.601504         0.611238        0.010287   \n",
       "105           0.584270           0.612782         0.610003        0.019974   \n",
       "37            0.599251           0.593985         0.608732        0.017266   \n",
       "68            0.595506           0.593985         0.607483        0.018025   \n",
       "3             0.621723           0.582707         0.607469        0.017576   \n",
       "129           0.621723           0.609023         0.606253        0.013900   \n",
       "95            0.554307           0.672932         0.605085        0.049910   \n",
       "69            0.602996           0.612782         0.603761        0.007074   \n",
       "92            0.558052           0.609023         0.598763        0.029944   \n",
       "38            0.573034           0.590226         0.598739        0.025194   \n",
       "29            0.580524           0.631579         0.597543        0.024067   \n",
       "35            0.610487           0.582707         0.597482        0.011410   \n",
       "125           0.591760           0.612782         0.596271        0.012069   \n",
       "130           0.584270           0.593985         0.596247        0.010822   \n",
       "\n",
       "     rank_test_score            preprocessor vectorizer  \n",
       "96                 1  TextPreprocessorSTEM()      Count  \n",
       "97                 2  TextPreprocessorSTEM()      Count  \n",
       "1                  1   TextPreprocessorLEM()      Count  \n",
       "36                 1   TextPreprocessorLEM()     Tf-Idf  \n",
       "104                1  TextPreprocessorSTEM()     Tf-Idf  \n",
       "93                 3  TextPreprocessorSTEM()      Count  \n",
       "0                  2   TextPreprocessorLEM()      Count  \n",
       "105                2  TextPreprocessorSTEM()     Tf-Idf  \n",
       "37                 2   TextPreprocessorLEM()     Tf-Idf  \n",
       "68                 4  TextPreprocessorSTEM()      Count  \n",
       "3                  3   TextPreprocessorLEM()      Count  \n",
       "129                3  TextPreprocessorSTEM()     Tf-Idf  \n",
       "95                 5  TextPreprocessorSTEM()      Count  \n",
       "69                 6  TextPreprocessorSTEM()      Count  \n",
       "92                 7  TextPreprocessorSTEM()      Count  \n",
       "38                 3   TextPreprocessorLEM()     Tf-Idf  \n",
       "29                 4   TextPreprocessorLEM()      Count  \n",
       "35                 4   TextPreprocessorLEM()     Tf-Idf  \n",
       "125                4  TextPreprocessorSTEM()     Tf-Idf  \n",
       "130                5  TextPreprocessorSTEM()     Tf-Idf  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_models_df2 = grid_search2_df.sort_values(by='mean_test_score', ascending=False).head(20)\n",
    "top_models_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, random_state=53)                                    11\n",
       "GradientBoostingClassifier(max_depth=10, n_estimators=50, random_state=53)     9\n",
       "Name: param_classifier, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_models_df2['param_classifier'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextPreprocessorSTEM()    12\n",
       "TextPreprocessorLEM()      8\n",
       "Name: preprocessor, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_models_df2['preprocessor'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Count     11\n",
       "Tf-Idf     9\n",
       "Name: vectorizer, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_models_df2['vectorizer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so far, count vectorizer, GBTrees classifier, and stemming providing best accuracy scores. try a model with 100k rows on this combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_models_stem_list = []\n",
    "top_models_lem_list = []\n",
    "for index, row in top_models_df.iterrows():\n",
    "    if row['preprocessor'] == 'TextPreprocessorSTEM()':\n",
    "        model_params = {}\n",
    "\n",
    "        for param_name, param_value in row['params'].items():\n",
    "            model_params[param_name] = param_value\n",
    "        top_models_stem_list.append(model_params)\n",
    "    else:\n",
    "        model_params = {}\n",
    "\n",
    "        for param_name, param_value in row['params'].items():\n",
    "            model_params[param_name] = param_value\n",
    "        top_models_lem_list.append(model_params)\n",
    "        \n",
    "#gridsearch_params3 = {\n",
    "#    'param_name': top_models_list\n",
    "#}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizing best scores from GridSearchCV n=1,000 amd n=10,000\n",
    "\n",
    "#### Due to processing speeds and time constraints, going to manually focus on the following:\n",
    "1. Stemming the texts - proportionally higher accuracy, and faster processing speed\n",
    "1. Count Vectorizer - faster processing speed\n",
    "    1. going to assess different features at `n` different min_df\n",
    "    1. `n_gram` set to (1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50158\n",
       "1    49842\n",
       "Name: is_open, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slightly higher sample size\n",
    "samp_df3 = train_df.sample(frac=1.0, random_state=53).head(100000)\n",
    "samp_df3['is_open'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform the train-test split \n",
    "X3 = samp_df3.drop('is_open', axis=1)\n",
    "y3 = samp_df3['is_open']\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size = 0.2, random_state = 53)\n",
    "\n",
    "#preprocess X_train with the two classes\n",
    "#create instances of all processors:\n",
    "proc_stem3 = TextPreprocessorSTEM()\n",
    "\n",
    "#create dataframes with Stemmed data\n",
    "X_train_stem3 = proc_stem3.fit_transform(X_train3['text'])\n",
    "test_stem3 = proc_stem3.transform(X_test3['text'])\n",
    "\n",
    "#create dataframes with lemmed data\n",
    "#X_train_lem3 = proc_lem3.fit_transform(X_train3) \n",
    "#test_lem3 = proc_lem3.transform(X_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframes with lemmed data\n",
    "#proc_lem3 = TextPreprocessorLEM()\n",
    "#X_train_lem3 = proc_lem3.fit_transform(X_train3) \n",
    "#test_lem3 = proc_lem3.transform(X_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing different vectorization techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 893)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer3_1a = CountVectorizer(min_df=0.01, max_df=0.99, ngram_range=(1, 5))\n",
    "X_3_1a = vectorizer3_1a.fit_transform(X_train_stem3)\n",
    "X_3_1a = pd.DataFrame.sparse.from_spmatrix(X_3_1a)\n",
    "X_3_1a = pd.concat([X_train3[other_cols].reset_index(drop=True), X_3_1a], axis=1)\n",
    "X_3_1a = csr_matrix(X_3_1a.values)\n",
    "\n",
    "X_test_3_1 = vectorizer3_1a.transform(test_stem3)\n",
    "X_test_3_1 = pd.DataFrame.sparse.from_spmatrix(X_test_3_1)\n",
    "X_test_3_1 = pd.concat([X_test3[other_cols].reset_index(drop=True), X_test_3_1], axis=1)\n",
    "X_test_3_1 = csr_matrix(X_test_3_1.values)\n",
    "\n",
    "X_3_1a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the vectorizer for future use\n",
    "with open('count_vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(vectorizer3_1a, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 890)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer3_2 = CountVectorizer(min_df=0.01, max_df=0.99, ngram_range=(1, 4))\n",
    "X_3_2 = vectorizer3_2.fit_transform(X_train_stem3)\n",
    "X_test_3_2 = vectorizer3_2.transform(test_stem3)\n",
    "X_3_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 7129)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer3_3 = TfidfVectorizer(min_df=0.001, max_df=0.999, ngram_range=(1, 4))\n",
    "X_3_3 = vectorizer3_3.fit_transform(X_train_stem3)\n",
    "X_test_3_3 = vectorizer3_3.transform(test_stem3)\n",
    "X_3_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.7701396932124001\n"
     ]
    }
   ],
   "source": [
    "model3_1a = GradientBoostingClassifier(max_depth=10, n_estimators=100, random_state=53) \n",
    "model3_1a.fit(X_3_1a, y_train3)\n",
    "y_pred3_1a = model3_1a.predict_proba(X_test_3_1)[:, 1]\n",
    "roc_auc3_1a = roc_auc_score(y_test3, y_pred3_1a)\n",
    "print(\"ROC AUC Score:\", roc_auc3_1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GB_model_100k_yelp.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model3_1a, 'GB_model_100k_yelp.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAEGCAYAAAAT05LOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAe9ElEQVR4nO3deZRcZZ3/8fen1+x7yM4ewYASIAYQRRYxQYfFUcaASo4ygzC4zIziAA4uzEQZkZ8CChoWCQPIREWIqCwTiYAHCAkCgQCmIUBCAiGdhOxJd9f390fdjpWklyro6qqu+3mdc0/f+9Rz732qc/qbZ7vPVURgZpY2VaUugJlZKTj4mVkqOfiZWSo5+JlZKjn4mVkq1ZS6ALmGDamOvcfVlroYVoC/Pt2n1EWwAmxlE9tjm97JNaYc1zca17TklXfh09vujYip7+R+xVJWwW/vcbXMv3dcqYthBZgyemKpi2AFeCzmvuNrNK5pYf69e+aVt3rUkmHv+IZFUlbBz8zKXwAZMqUuxjvm4GdmBQmCpsiv2VvOHPzMrGCu+ZlZ6gRBSwU8FuvgZ2YFy+DgZ2YpE0CLg5+ZpZFrfmaWOgE0uc/PzNImCDd7zSyFAlp6fuzzwgZmVpjsEx75bR2RdICkJ3O29ZL+RdIQSfdLWpL8HJxzzkWSGiS9IGlKTvrhkhYln10lqdPnlx38zKxAoiXPrSMR8UJETIyIicDhwGbgN8CFwNyIGA/MTY6RNAGYBhwETAWukVSdXO5a4BxgfLJ1upiCg5+ZFSQ74KG8tgKcALwYEa8ApwKzkvRZwGnJ/qnA7RGxLSKWAg3AZEmjgAER8UhkX0p0c8457XKfn5kVJDvP7x2titWWacAvkv0REbESICJWStojSR8DPJpzzvIkrSnZ3zW9Qw5+ZlawTP61umGSFuQcz4yImbkZJNUBpwAXdXKttm4aHaR3yMHPzApSYM1vdURM6iTPScATEfFGcvyGpFFJrW8UsCpJXw7kLvg5FliRpI9tI71D7vMzs4IEooWqvLY8ncHfmrwAc4Dpyf504K6c9GmS6iXtQ3ZgY37SRN4g6chklPesnHPa5ZqfmRWsgGZvhyT1AU4EvpCTfBkwW9LZwKvA6QAR8ayk2cBioBk4P2LHwoLnATcBvYE/JFuHHPzMrCCB2B7VnWfM51oRm4Ghu6Q1kh39bSv/DGBGG+kLgIMLubeDn5kVJDvJuef3mDn4mVnBijDVpds5+JlZQSJES7jmZ2YplHHNz8zSJjvg0fNDR8//BmbWrTzgYWap1dJF8/xKycHPzArS+oRHT+fgZ2YFy3i018zSJruwgYOfmaVMIJq66PG2UnLwM7OCROBJzmaWRvIkZzNLn8A1PzNLKQ94mFnqBOqyxUxLycHPzAqSfXVlzw8dPf8bmFk36/yF5D2Bg5+ZFSTwEx5mllKu+ZlZ6kTINT8zS5/sgIcfbzOz1PE7PMwshbIDHu7zM7MU8hMeZpY6fsLDzFLLLzAys9SJgKaMg5+ZpUy22evgZ2Yp5Cc8UmpZQz3fPXfvHcevv1rHZy94nQ1rq3nk3oFIMGhYE1/70asMHdnMwj/148bvjqa5SdTUBv90yQomfmDjTtf81vR9WPlqHTMfeKGbv006DB+9nQuufJXBezQTGfj9LUO584bhXPzTlxm73zYA+g5oYdP6av75xAPoP7iZS2a+zLsmbuH+2YP5yTfG7rjWjFtfYsgeTVTXBM881o8fXzyGTKbnB4N8eapLHiRNBa4EqoHrI+KyYt6vu4zbfxvX/l82SLW0wKcPO4ijT1pHv4EtTP/66wDcef0wbvnhSL7y38sZOKSFS2e9xNCRzbz8fC8uPnNfbnti8Y7rPfz7gfTqmynJd0mLlmYx89LRNCzqQ+++Lfz4nr/yxIP9d/pP7JxvrmDThmxzbvtWMevykex9wFb2PnDrTtea8YW92LyxGgguue4VPnjyOv501+Bu/DalVhnN3qJ9A0nVwE+Ak4AJwBmSJhTrfqXy5EP9GbXXNkaMbaJv/78FsK1bqlDyn+P+79nC0JHNAOx1wFa2b6ti+7bsh1s2VXHHz4Zz5r+83u1lT5M1q2ppWNQHgC2bqlnW0Itho5pycgTHnLKOB+7MBrFtW6p5dn4/tm/b/U8kG/igugZq6iJbFUqZTPIej862clbMmt9koCEiXgKQdDtwKrC4w7N6mHl3DeLY09btOP75ZSP5v18Ooe+AFr7/q4bd8j/8u4Hsd9AW6uqzfzGzvj+ST5z7JvW9U/gXVCIjxm5nv4O38PwTfXakHXzEJta+WcOKpfV5XWPGbS9ywMQtLHigPw/dPahIJS1P2dHenv9sbzHrrmOAZTnHy5O0nUg6R9ICSQvebGwpYnG6XtN28eh9Aznm5HU70j534evcunAxx//9WubcOHyn/C+/0IsbZozmK9/P/lpefKY3K5bWc/RJb3VnsVOtV58WLrn+ZX76zdE7anAAx522jnl3Dsr7Ot84cz/OOHQCtXWxW/9tpWud5JzPVs6KGfza+ua7VW8iYmZETIqIScOH9qz/TR7/Y3/2f89mBg9v3u2z4z6+lod/P3DH8Zsrarn07L254MpXGb33dgAWL+zDkkV9OGvyBL562v689lI9F3xi/24rf9pU1wSXXP8yf7xjMH/+w6Ad6VXVwdEffYs/zRnU7rltadpWxSP3DeCoKen7z8vN3o4tB8blHI8FVhTxft1u3p2Dd2ryvvZSHWP2zQa2R+8dyLj9s6OIG9+q5pKz9uVzF63koMmbduQ/eXojJ09vBOD1ZXV886x9uPzXuzeVrSsE/3bFMpYt6cUdM3eukR/2wQ0sa6hn9cq6Tq/Sq08LffplWLOqlqrqYPIJ63nmsX7FKnRZ8mhv5x4HxkvaB3gNmAacWcT7dautm8UTD/Xf0YQFuOG7o1n+Yj1VVbDHmO18+b+XAzDn58NYsbSO2344ktt+OBKA793+IoOG7V5jtOI4aPImPnz6Wl5a3Itr7s+O1P/8e6N4/I8D+NCpbTd5Zz22mL79MtTUBUdNWc/FZ+zL+rXVfPumpdTWBdXVwZN/7sfdNw/t5m9TepUw2quI4nW0S/oo8COyU11ujIgZHeWfdEivmH/vuI6yWJmZMnpiqYtgBXgs5rI+1ryjatvgA/eI42/8ZF557zj62oURMemd3K9Yihq+I+L3EfGuiNivs8BnZj1HVw14SBok6VeSnpf0nKSjJA2RdL+kJcnPwTn5L5LUIOkFSVNy0g+XtCj57CpJnd6859ddzaxbtfb5ddFo75XAPRFxIHAI8BxwITA3IsYDc5NjknnC04CDgKnANcl8YoBrgXOA8ck2tbMbO/iZWcG6IvhJGgAcA9wAEBHbI2Id2fnAs5Jss4DTkv1TgdsjYltELAUagMmSRgEDIuKRyPbj3ZxzTrsc/MysIAXO8xvWOo832c7JudS+wJvAzyX9RdL1kvoCIyJiJUDyc48kf3tzh8ck+7umd8gLG5hZwQqYw7e6gwGPGuAw4EsR8ZikK0mauO1ob+5wXnOKd+Wan5kVJAKaM1V5bZ1YDiyPiMeS41+RDYZvJE1Zkp+rcvK3NXd4ebK/a3qHHPzMrGBd0ecXEa8DyyQdkCSdQPbZ/znA9CRtOnBXsj8HmCapPpk/PB6YnzSNN0g6MhnlPSvnnHa52WtmBeniFxh9CbhVUh3wEvA5spWy2ZLOBl4FTgeIiGclzSYbIJuB8yOidUGA84CbgN7AH5KtQw5+Zlaw6KLgFxFPAm31CZ7QTv4ZwG5zhiNiAXBwIfd28DOzgpX7ogX5cPAzs4JEeGEDM0sl0eJXV5pZGnVVn18pOfiZWUG8np+ZpVNk+/16Ogc/MyuYR3vNLHXCAx5mllZu9ppZKnm018xSJ8LBz8xSylNdzCyV3OdnZqkTiIxHe80sjSqg4ufgZ2YF8oCHmaVWBVT9HPzMrGAVXfOTdDUdxPeI+HJRSmRmZS2ATKaCgx+woNtKYWY9RwCVXPOLiFm5x5L6RsSm4hfJzMpdJczz63SyjqSjJC0GnkuOD5F0TdFLZmblK/Lcylg+MxV/BEwBGgEi4ingmCKWyczKmojIbytneY32RsSy7IvQd2hpL6+ZpUCZ1+rykU/wWybp/UAkb1X/MkkT2MxSKCAqYLQ3n2bvucD5wBjgNWBicmxmqaU8t/LVac0vIlYDn+6GsphZT1EBzd58Rnv3lfRbSW9KWiXpLkn7dkfhzKxMpWS09zZgNjAKGA38EvhFMQtlZmWsdZJzPlsZyyf4KSL+JyKak+0Wyj6mm1kxReS3lbOOnu0dkuw+IOlC4HayQe9TwO+6oWxmVq4qYLS3owGPhWSDXeu3/ELOZwH8Z7EKZWblTWVeq8tHR8/27tOdBTGzHqIHDGbkI68nPCQdDEwAerWmRcTNxSqUmZWz8h/MyEenwU/St4BjyQa/3wMnAQ8DDn5maVUBNb98Rns/CZwAvB4RnwMOAeqLWiozK2+ZPLcylk+zd0tEZCQ1SxoArAI8ydksrSp9MdMcCyQNAq4jOwK8EZhfzEKZWXmrhNHeTpu9EfHPEbEuIn4KnAhMT5q/ZpZWXfR4m6SXJS2S9KSkBUnaEEn3S1qS/Byck/8iSQ2SXpA0JSf98OQ6DZKu0i5r8LWl3eAn6bBdN2AIUJPsm5l1heMiYmJETEqOLwTmRsR4YG5yjKQJwDTgIGAqcI2k6uSca4FzgPHJNrWzm3bU7L2ig88COL6zixdqyZIhnDR1Wldf1oroH56bV+oiWAGWfKKpS65T5GbvqWRnmADMAuYB/56k3x4R24ClkhqAyZJeBgZExCMAkm4GTgP+0NFNOprkfNw7Kr6ZVaagkMfbhrU2ZxMzI2LmLle7T1IAP0s+GxERKwEiYqWkPZK8Y4BHc85dnqQ1Jfu7pnfILy03s8LlX/NbndOcbcvREbEiCXD3S3q+g7xtRdzoIL1D+czzMzPbiSK/rTMRsSL5uQr4DTAZeEPSKIDk56ok+3JgXM7pY4EVSfrYNtI75OBnZoXrgtFeSX0l9W/dBz4CPAPMAaYn2aYDdyX7c4Bpkuol7UN2YGN+0kTeIOnIZJT3rJxz2pXP420iu4z9vhFxqaQ9gZER4bl+ZmnVNQMeI4DfJLNSaoDbIuIeSY8DsyWdDbwKnA4QEc9Kmg0sBpqB8yOi9U2S5wE3Ab3JDnR0ONjResPOXEP2QZXjgUuBDcCvgffl+QXNrILk26TtTES8RPZx2V3TG8k+UtvWOTOAGW2kLwAOLuT++QS/IyLiMEl/SW6yNnmFpZmlVYUvZtqqKZlIGACShlP2jyybWTGl4vE24CqyozB7SJpBdjmr7xa1VGZW3irg7W35vLf3VkkLybbBBZwWEc8VvWRmVp66qM+v1PIZ7d0T2Az8NjctIl4tZsHMrIylIfiRfVNb6yzqXsA+wAtkHy42sxRSBfT659PsfU/ucbKiyxfayW5m1iMU/GxvRDwhyXP8zNIsDc1eSf+Wc1gFHAa8WbQSmVl5S8uAB9A/Z7+ZbB/gr4tTHDPrESo9+CWTm/tFxAXdVB4z6wkqOfhJqomIZi9Zb2a5ROWP9s4n27/3pKQ5wC+BTa0fRsQdRS6bmZWjFPX5DQEaya7q0jrfLwAHP7O0qvDgt0cy0vsMuy8VXQFf3czetgqIAB0Fv2qgH29zfXwzq1yV3uxdGRGXdltJzKznqPDg1/NXKzSzrheVP9rb5jLSZmYVXfOLiDXdWRAz6zkqvc/PzKxtDn5mljo9YIn6fDj4mVlBhJu9ZpZSDn5mlk4OfmaWSg5+ZpY6KVrVxcxsZw5+ZpZGlf54m5lZm9zsNbP08SRnM0stBz8zSxs/4WFmqaVMz49+Dn5mVhj3+ZlZWrnZa2bp5OBnZmlUCTW/qlIXwMx6oMhzy4Okakl/kXR3cjxE0v2SliQ/B+fkvUhSg6QXJE3JST9c0qLks6skdfoCNgc/MytM8va2fLY8fQV4Luf4QmBuRIwH5ibHSJoATAMOAqYC10iqTs65FjgHGJ9sUzu7qYOfmRWkdZ5fPlun15LGAh8Drs9JPhWYlezPAk7LSb89IrZFxFKgAZgsaRQwICIeiYgAbs45p13u8zOzwkXenX7DJC3IOZ4ZETNzjn8EfB3on5M2IiJWZm8TKyXtkaSPAR7Nybc8SWtK9ndN75CDn5kVrIABj9URManNa0h/B6yKiIWSjs3ntm2kRQfpHXLwextqa1u4/Ad/pLa2herq4OGHxnHLLQfz2bMWcdRRr5HJiLfW1XPFFUewZk1vDj30dT73+aepqcnQ3FzFDdcfwlNPjQDgQ8e+wqc+le3uaGzszeXfP5L16+tL+fUq1vb1YsElA3lrSQ0I3vdfbzHs0CaW3NKHhlv7oOpg1Ie2ccgFG2l8upaF3xoAZCs5B52/kbEnbgPggbOGsPXNKqp7Zf++jrl+Lb2GVsAaT/nquknORwOnSPoo0AsYIOkW4A1Jo5Ja3yhgVZJ/OTAu5/yxwIokfWwb6R0qWvCTdCPQGtkPLtZ9SqGpqYoL//1Ytm6tpbo6ww+umMuCBSP59a8O5H9ufg8Ap5z6V8789LP8+OpJrF9fz7e/9UHWrOnNXnut479mPMhnP3MKVVUZzj33L3zhnJNYv76ez5/9FCefsoRbb6moX1fZ+Mt3BzDyA9t4/5XraNkOLVvFqsfqeG1uPR+5azXVdbC1MdsNPnB8Ex/+ZSNVNbBlVRX3fXwoo497k6rkL+aIy9cx5ODmEn6b0uqK9fwi4iLgIoCk5ve1iPiMpMuB6cBlyc+7klPmALdJ+n/AaLIDG/MjokXSBklHAo8BZwFXd3b/Yg543EQeIy49k9i6tRaAmpoMNTUZIsTmzbU7cvTq1bzjf8cXXxzMmjW9AXjllYHU1bVQW9uClK2v9+rVDAR9+jSxprF3N3+XdGjaKFYvqGWfT24BoLoO6gYEDbf35t3/tInqumy+1hpcTW92BLqW7Wq7YZViXTzau6vLgBMlLQFOTI6JiGeB2cBi4B7g/IhoSc45j+ygSQPwIvCHzm5StJpfRDwoae9iXb/UqqoyXHX1/YwevZG7f7s/L7wwFIDp05/mhA+/zKZNtVz478ftdt4HPrCcF18cTFNTdoT+xz8+nGuvvYet22p47bX+XPOTw7r1e6TFxmXV1A/J8PjFA1n3Qg2DJzRx6MUb2PhyDW8urGPRlf2oroNDvr6eIe/J1ugan6rl8W8MYPPKaiZf9taOYAjw+MUDUTWMOXErE87bROezyipIUMiAR36XjJgHzEv2G4ET2sk3A5jRRvoCoKAmU8mnukg6R9ICSQu2N28qdXHylslU8cXzp/DZz5zMuw5Yw157rQNg1qz3ctZnT+GBB/bi5JMbdjpnz73e4vOff4qrr8r2/1ZXZ/jYxxr44hen8OkzT2Hp0oH8w6ee2/VW1gWiBdYurmW/aZv5yB2N1PQJnruuL5nmbF/gCbev4b0XbOCRfx204+966CFNTL27kQ/PbuT56/rSku3y44jL1zFlTiPH3bKG1QvreOWuXqX7YiXSVVNdSqnkwS8iZkbEpIiYVFfTt9TFKdimTXU8/fRwJk16faf0eQ/sxdEfWLbjeNiwzVxyycP84AdHsHJlPwD2228tQHIsHnpwHBPe3dhtZU+T3iMy9B6RYeghTQCM/chW1i2uoc/IDGNP3IYEQ9/bBFWwbe3O1bgB+7VQ3TuyAyVAnxHZ9lxt32DPv9vKmkW1pE4XPuFRKiUPfj3RwIFb6dt3OwB1dc0ceugbLFs2gNGjN+zIc+SRr7F8WXa0sG/f7Xzn0ge56efvZfHi4TvyrF7dhz33Ws/AgVsBOPSwN3h1We50J+sqvYdn6DOqhfVLs90Nbzxaz4D9Wxh9wlZWPZrt8NuwtJpMk6gfHGxcXk0mGc/Y9FoVG5bW0HdMC5nmvwXHTBOsnFfPgPHpGvjoyknOpeSpLm/D4CFb+dpXH6OqOpCChx7ck/nzR/ON//gzY8euJ0KseqMvV199OAAnn7KE0aM3csaZiznjzMUAfOPiD7FmTW9uveUgvn/5H2lpqWLVG3254orJpfxqFe3Qb6znsQsGkWmCvuNamDzjLap7B4//x0DuOXkoVbUw+XtvIcHqhbU8f90gqmoBweHfXE/94KB5s3jwH4eQac42pUe8fzv7nr6l1F+te0VUxGKmii7uuNxxYekXwLHAMOAN4FsRcUNH5wzsMzqOfNfZRSmPFccn/3deqYtgBZjxiSd5+ZkN72h4pv+gsXHoMV/JK+9Dv/36wvYmOZdaMUd7zyjWtc2stMq9SZsPN3vNrDABVECz18HPzArX82Ofg5+ZFc7NXjNLpUoY7XXwM7PC9IAJzPlw8DOzgmQnOff86OfgZ2aFq4DlCx38zKxgrvmZWfq4z8/M0qkynu118DOzwrnZa2apE13zDo9Sc/Azs8K55mdmqdTzY5+Dn5kVTpme3+518DOzwgSe5Gxm6SPCk5zNLKUc/MwslRz8zCx13OdnZmnl0V4zS6Fws9fMUihw8DOzlOr5rV4HPzMrnOf5mVk6OfiZWepEQEvPb/c6+JlZ4VzzM7NUcvAzs9QJwO/wMLP0CQj3+ZlZ2gQVMeBRVeoCmFkPFJHf1gFJvSTNl/SUpGclfSdJHyLpfklLkp+Dc865SFKDpBckTclJP1zSouSzqySps6/g4GdmheuC4AdsA46PiEOAicBUSUcCFwJzI2I8MDc5RtIEYBpwEDAVuEZSdXKta4FzgPHJNrWzmzv4mVmB8gx8nQS/yNqYHNYmWwCnArOS9FnAacn+qcDtEbEtIpYCDcBkSaOAARHxSEQEcHPOOe1y8DOzwgSQyeS3wTBJC3K2c3IvJala0pPAKuD+iHgMGBERKwGSn3sk2ccAy3JOX56kjUn2d03vkAc8zKxw+c/zWx0Rk9q/TLQAEyUNAn4j6eAOrtVWP150kN4hBz8zK1DXP94WEeskzSPbV/eGpFERsTJp0q5Ksi0HxuWcNhZYkaSPbSO9Q272mllhAiIyeW0dkTQ8qfEhqTfwYeB5YA4wPck2Hbgr2Z8DTJNUL2kfsgMb85Om8QZJRyajvGflnNMu1/zMrHBd84THKGBWMmJbBcyOiLslPQLMlnQ28CpwOkBEPCtpNrAYaAbOT5rNAOcBNwG9gT8kW4cc/MyscF3wbG9EPA0c2kZ6I3BCO+fMAGa0kb4A6Ki/cDcOfmZWmIjWkdwezcHPzArnVV3MLH2CaGnpPFuZc/Azs8J4SSszSy0vaWVmaRNAuOZnZqkTXszUzFKqEgY8FGU0ZC3pTeCVUpejCIYBq0tdCCtIpf6b7RURw9/JBSTdQ/b3k4/VEdHp2nqlUFbBr1JJWtDRyhZWfvxvVvm8sIGZpZKDn5mlkoNf95hZ6gJYwfxvVuHc52dmqeSan5mlkoOfmaWSg18RSZqavFy5QdKFpS6PdU7SjZJWSXqm1GWx4nLwK5Jkae6fACcBE4AzkpcuW3m7iTxeeG09n4Nf8UwGGiLipYjYDtxO9qXLVsYi4kFgTanLYcXn4Fc87b1g2czKgINf8bytFymbWfdw8Cue9l6wbGZlwMGveB4HxkvaR1IdMI3sS5fNrAw4+BVJRDQDXwTuBZ4j+0LmZ0tbKuuMpF8AjwAHSFqevDjbKpAfbzOzVHLNz8xSycHPzFLJwc/MUsnBz8xSycHPzFLJwa8HkdQi6UlJz0j6paQ+7+BaN0n6ZLJ/fUeLLkg6VtL738Y9Xpa021u+2kvfJc/GAu/1bUlfK7SMll4Ofj3LloiYGBEHA9uBc3M/TFaSKVhE/GNELO4gy7FAwcHPrJw5+PVcDwH7J7WyByTdBiySVC3pckmPS3pa0hcAlPVjSYsl/Q7Yo/VCkuZJmpTsT5X0hKSnJM2VtDfZIPuvSa3zg5KGS/p1co/HJR2dnDtU0n2S/iLpZ7T9fPNOJN0paaGkZyWds8tnVyRlmStpeJK2n6R7knMeknRgl/w2LXVqSl0AK5ykGrLrBN6TJE0GDo6IpUkAeSsi3iepHvizpPuAQ4EDgPcAI4DFwI27XHc4cB1wTHKtIRGxRtJPgY0R8YMk323ADyPiYUl7kn2K5d3At4CHI+JSSR8Ddgpm7fh8co/ewOOSfh0RjUBf4ImI+KqkbybX/iLZFwudGxFLJB0BXAMc/zZ+jZZyDn49S29JTyb7DwE3kG2Ozo+IpUn6R4D3tvbnAQOB8cAxwC8iogVYIemPbVz/SODB1mtFRHvr2n0YmCDtqNgNkNQ/ucffJ+f+TtLaPL7TlyV9PNkfl5S1EcgA/5uk3wLcIalf8n1/mXPv+jzuYbYbB7+eZUtETMxNSILAptwk4EsRce8u+T5K50tqKY88kO0uOSoitrRRlryfl5R0LNlAelREbJY0D+jVTvZI7rtu19+B2dvhPr/Kcy9wnqRaAEnvktQXeBCYlvQJjgKOa+PcR4APSdonOXdIkr4B6J+T7z6yTVCSfBOT3QeBTydpJwGDOynrQGBtEvgOJFvzbFUFtNZezyTbnF4PLJV0enIPSTqkk3uYtcnBr/JcT7Y/74nkJTw/I1vD/w2wBFgEXAv8adcTI+JNsv10d0h6ir81O38LfLx1wAP4MjApGVBZzN9Gnb8DHCPpCbLN71c7Kes9QI2kp4H/BB7N+WwTcJCkhWT79C5N0j8NnJ2U71n8agB7m7yqi5mlkmt+ZpZKDn5mlkoOfmaWSg5+ZpZKDn5mlkoOfmaWSg5+ZpZK/x/Lufmq/KBBdwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(model3_1a, X_test_3_1, y_test3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x162f1058d00>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(model3_1a, X_test_3_1, y_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final check on hyper-parameters of the Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.6356798969942059\n"
     ]
    }
   ],
   "source": [
    "logreg3_4 = LogisticRegression(penalty='l2', C=0.1, max_iter=1000)\n",
    "\n",
    "logreg3_4.fit(X_3_1, y_train3)\n",
    "y_pred3_4 = logreg3_4.predict_proba(X_test_3_1)[:, 1]\n",
    "roc_auc3_4 = roc_auc_score(y_test3, y_pred3_4)\n",
    "print(\"ROC AUC Score:\", roc_auc3_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running entire dataset on entire training data, and predicting on holdout\n",
    "\n",
    "NOTE: while the full dataset was run below, due to memory and time constraints, the models were run using only the review text data, and not additional attributes. this resulted in a lower score, and will be re-run once time resources are freed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-464fd1f0686f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mproc_stem_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextPreprocessorSTEM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#create dataframes with Stemmed data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_train_stem_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc_stem_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtest_stem_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc_stem_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    688\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 690\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    691\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-c14a79dea437>\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, data, y)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mfully_normalized_corpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_doc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfully_normalized_corpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4198\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4200\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-c14a79dea437>\u001b[0m in \u001b[0;36mprocess_doc\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprocess_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mstemmer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSnowballStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mtext_cleaning_re\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py\u001b[0m in \u001b[0;36mwords\u001b[1;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[0;32m     21\u001b[0m         return [\n\u001b[0;32m     22\u001b[0m             \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mignore_lines_startswith\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         ]\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py\u001b[0m in \u001b[0;36mraw\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mfileids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mfileids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\nltk\\corpus\\reader\\api.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m    207\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, encoding)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m         \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeekableUnicodeStreamReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "proc_stem_full = TextPreprocessorSTEM()\n",
    "#create dataframes with Stemmed data\n",
    "X_train_stem_full = proc_stem_full.fit_transform(X['text'])\n",
    "test_stem_full = proc_stem_full.transform(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1466627    place amaz roast bone marrow mac chees unexpec...\n",
       "725299     decent lunch standard breakfast way go smoke s...\n",
       "703075     felt much desir littl colleg restaur concept g...\n",
       "1946293    figur time tread maoz sinc basic across street...\n",
       "1205881    one best spas northsid indi person servic prov...\n",
       "                                 ...                        \n",
       "1303570    cosi rock conveni usual get pretti quick even ...\n",
       "2257722    last year host parti restaur everyth fine exce...\n",
       "1639564    enough room tell wonder tamira restaur cater h...\n",
       "1322170    french cuisin favorit restaur nice nice worri ...\n",
       "189213     facial microdermabras massag assuag better eve...\n",
       "Name: text, Length: 1918473, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_stem_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stem_full.to_csv('X_train_stem_full.csv')\n",
    "test_stem_full.to_csv('test_stem_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stem_full = pd.read_csv('../X_train_stem_full.csv')\n",
    "test_stem_full = pd.read_csv('../test_stem_full.csv')\n",
    "\n",
    "X_train_stem_full.set_index(\"Unnamed: 0\", inplace=True)\n",
    "#X_train_stem_full.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "test_stem_full.set_index(\"Unnamed: 0\", inplace=True)\n",
    "#test_stem_full.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stem_full['text'].fillna('', inplace=True)\n",
    "test_stem_full['text'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "vectorizer_full1 = HashingVectorizer(n_features=3000)\n",
    "X_full1 = vectorizer_full1.fit_transform(X_train_stem_full['text'])\n",
    "\n",
    "X_test_full1 =  vectorizer_full1.transform(test_stem_full['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1918473, 3000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1918473, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 42.9 GiB for an array with shape (3003, 1918473) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-7ebce579bc47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX_full1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_spmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_full1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_full1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mother_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_full1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX_full1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_full1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#concatenating the non-text columns to the dataset - test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mvalues\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5341\u001b[0m         \"\"\"\n\u001b[0;32m   5342\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5343\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5345\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mas_array\u001b[1;34m(self, transpose, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m    851\u001b[0m                     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 853\u001b[1;33m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    854\u001b[0m             \u001b[1;31m# The underlying data was copied within _interleave\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m    880\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"object\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m         \u001b[0mitemmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 42.9 GiB for an array with shape (3003, 1918473) and data type float64"
     ]
    }
   ],
   "source": [
    "#concatenating the non-text columns to the dataset - train data\n",
    "X_full1 = pd.DataFrame.sparse.from_spmatrix(X_full1)\n",
    "X_full1 = pd.concat([X[other_cols].reset_index(drop=True), X_full1], axis=1)\n",
    "X_full1 = csr_matrix(X_full1.values)\n",
    "\n",
    "#concatenating the non-text columns to the dataset - test data\n",
    "X_test_full1 = pd.DataFrame.sparse.from_spmatrix(X_test_full1)\n",
    "X_test_full1 = pd.concat([X_test[other_cols].reset_index(drop=True), X_test_full1], axis=1)\n",
    "X_test_full1 = csr_matrix(X_test_full1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_clf_full = GradientBoostingClassifier(max_depth=10, n_estimators=100, random_state=53, verbose=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3796          670.00m\n",
      "         2           1.3739          670.42m\n",
      "         3           1.3691          647.86m\n",
      "         4           1.3648          641.56m\n",
      "         5           1.3611          631.98m\n",
      "         6           1.3578          624.33m\n",
      "         7           1.3546          625.89m\n",
      "         8           1.3519          620.08m\n",
      "         9           1.3491          619.80m\n",
      "        10           1.3468          607.21m\n",
      "        11           1.3444          604.66m\n",
      "        12           1.3424          591.75m\n",
      "        13           1.3403          583.91m\n",
      "        14           1.3384          575.82m\n",
      "        15           1.3366          564.93m\n",
      "        16           1.3349          551.38m\n",
      "        17           1.3333          539.35m\n",
      "        18           1.3318          528.52m\n",
      "        19           1.3303          515.74m\n",
      "        20           1.3289          503.47m\n",
      "        21           1.3275          492.47m\n",
      "        22           1.3261          482.61m\n",
      "        23           1.3250          469.57m\n",
      "        24           1.3238          457.52m\n",
      "        25           1.3226          447.54m\n",
      "        26           1.3214          439.48m\n",
      "        27           1.3202          431.53m\n",
      "        28           1.3191          421.98m\n",
      "        29           1.3182          412.51m\n",
      "        30           1.3172          404.29m\n",
      "        31           1.3162          395.79m\n",
      "        32           1.3153          387.95m\n",
      "        33           1.3142          380.60m\n",
      "        34           1.3132          375.00m\n",
      "        35           1.3122          368.26m\n",
      "        36           1.3111          362.22m\n",
      "        37           1.3103          354.18m\n",
      "        38           1.3095          346.37m\n",
      "        39           1.3086          339.68m\n",
      "        40           1.3078          332.78m\n",
      "        41           1.3069          326.39m\n",
      "        42           1.3062          319.23m\n",
      "        43           1.3055          312.39m\n",
      "        44           1.3048          305.49m\n",
      "        45           1.3039          299.10m\n",
      "        46           1.3031          293.00m\n",
      "        47           1.3024          286.57m\n",
      "        48           1.3016          280.33m\n",
      "        49           1.3010          273.69m\n",
      "        50           1.3004          267.31m\n",
      "        51           1.2997          261.17m\n",
      "        52           1.2989          255.56m\n",
      "        53           1.2982          249.52m\n",
      "        54           1.2976          243.16m\n",
      "        55           1.2971          237.02m\n",
      "        56           1.2964          231.03m\n",
      "        57           1.2958          225.16m\n",
      "        58           1.2953          219.03m\n",
      "        59           1.2946          213.57m\n",
      "        60           1.2940          207.75m\n",
      "        61           1.2934          201.94m\n",
      "        62           1.2928          196.25m\n",
      "        63           1.2922          190.76m\n",
      "        64           1.2915          185.27m\n",
      "        65           1.2909          179.78m\n",
      "        66           1.2905          174.05m\n",
      "        67           1.2899          168.56m\n",
      "        68           1.2894          163.03m\n",
      "        69           1.2888          157.67m\n",
      "        70           1.2884          152.13m\n",
      "        71           1.2879          146.61m\n",
      "        72           1.2874          141.22m\n",
      "        73           1.2868          135.97m\n",
      "        74           1.2862          130.75m\n",
      "        75           1.2856          125.60m\n",
      "        76           1.2852          120.25m\n",
      "        77           1.2845          115.16m\n",
      "        78           1.2840          109.96m\n",
      "        79           1.2835          104.81m\n",
      "        80           1.2829           99.74m\n",
      "        81           1.2824           94.59m\n",
      "        82           1.2821           89.34m\n",
      "        83           1.2817           84.20m\n",
      "        84           1.2813           79.05m\n",
      "        85           1.2807           74.07m\n",
      "        86           1.2803           68.99m\n",
      "        87           1.2798           63.97m\n",
      "        88           1.2794           58.93m\n",
      "        89           1.2790           53.91m\n",
      "        90           1.2785           48.93m\n",
      "        91           1.2779           43.98m\n",
      "        92           1.2775           39.03m\n",
      "        93           1.2769           34.13m\n",
      "        94           1.2766           29.20m\n",
      "        95           1.2762           24.30m\n",
      "        96           1.2758           19.40m\n",
      "        97           1.2754           14.53m\n",
      "        98           1.2751            9.67m\n",
      "        99           1.2748            4.82m\n",
      "       100           1.2744            0.00s\n",
      "ROC AUC Score: 0.6093397470044621\n"
     ]
    }
   ],
   "source": [
    "GB_clf_full.fit(X_full1, y)\n",
    "\n",
    "GB_y_pred_full = GB_clf_full.predict(X_test_full1)\n",
    "GB_roc_auc_full = roc_auc_score(y_test, GB_y_pred_full)\n",
    "print(\"ROC AUC Score:\", GB_roc_auc_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(GB_clf_full, X_test_full1, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x119874c9ac0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(GB_clf_full, X_test_full1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GB_model_full_yelp.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(GB_clf_full, 'GB_model_full_yelp.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: below cells are archive cells of models tested, keeping for future reference but setting as non-executable."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sgd_clf = None"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(loss='log', alpha=0.01, max_iter=5000, random_state=53)\n",
    "batch_size = 50000\n",
    "num_batches = (X_full1.shape[0]) // batch_size\n",
    "\n",
    "# Perform partial fit on batches\n",
    "for batch_num in range(num_batches):\n",
    "    start_idx = batch_num * batch_size\n",
    "    end_idx = (batch_num + 1) * batch_size\n",
    "    X_batch = X_full1[start_idx:end_idx]\n",
    "    y_batch = y[start_idx:end_idx]\n",
    "    \n",
    "    # Partial fit the classifier with the current batch\n",
    "    sgd_clf.partial_fit(X_batch, y_batch, classes=np.unique(y))\n",
    "\n",
    "# If there's a remaining batch (in case len(X_train_full1) is not divisible by batch_size), perform partial fit on it\n",
    "if (X_full1.shape[0]) % batch_size != 0:\n",
    "    X_remaining = X_full1[num_batches * batch_size:]\n",
    "    y_remaining = y[num_batches * batch_size:]\n",
    "    sgd_clf.partial_fit(X_remaining, y_remaining, classes=np.unique(y))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_pred_full = sgd_clf.predict(X_test_full1)\n",
    "roc_auc_full = roc_auc_score(y_test, y_pred_full)\n",
    "print(\"ROC AUC Score:\", roc_auc_full)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import joblib\n",
    "full_model_filename = 'sgd_classifier_yelp.pkl'\n",
    "joblib.dump(sgd_clf, full_model_filename)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model3_1b = SGDClassifier(loss='log', alpha=0.01, max_iter=5000, random_state=53)\n",
    "model3_1b.fit(X_3_1a, y_train3)\n",
    "y_pred3_1b = model3_1b.predict_proba(X_test_3_1)[:, 1]\n",
    "roc_auc3_1b = roc_auc_score(y_test3, y_pred3_1b)\n",
    "print(\"ROC AUC Score:\", roc_auc3_1b)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "logreg3_1a = LogisticRegression(penalty='l2', C=1.0, max_iter=1000)\n",
    "logreg3_1a.fit(X_3_1a, y_train3)\n",
    "y_pred3_1a = logreg3_1a.predict_proba(X_test_3_1)[:, 1]\n",
    "roc_auc3_1a = roc_auc_score(y_test3, y_pred3_1a)\n",
    "print(\"ROC AUC Score:\", roc_auc3_1a)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "logreg3_1a1 = LogisticRegression(penalty='l2', C=0.01, max_iter=1000)\n",
    "logreg3_1a1.fit(X_3_1a, y_train3)\n",
    "y_pred3_1a1 = logreg3_1a1.predict_proba(X_test_3_1)[:, 1]\n",
    "roc_auc3_1a1 = roc_auc_score(y_test3, y_pred3_1a1)\n",
    "print(\"ROC AUC Score:\", roc_auc3_1a1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "logreg3_2 = LogisticRegression(penalty='l2', C=1.0, max_iter=1000)\n",
    "\n",
    "logreg3_2.fit(X_3_2, y_train3)\n",
    "y_pred3_2 = logreg3_2.predict_proba(X_test_3_2)[:, 1]\n",
    "roc_auc3_2 = roc_auc_score(y_test3, y_pred3_2)\n",
    "print(\"ROC AUC Score:\", roc_auc3_2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "logreg3_3 = LogisticRegression(penalty='l2', C=1.0, max_iter=1000)\n",
    "\n",
    "logreg3_3.fit(X_3_3, y_train3)\n",
    "y_pred3_3 = logreg3_3.predict_proba(X_test_3_3)[:, 1]\n",
    "roc_auc3_3 = roc_auc_score(y_test3, y_pred3_3)\n",
    "print(\"ROC AUC Score:\", roc_auc3_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
